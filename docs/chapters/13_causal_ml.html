<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Causal Machine Learning – Mastering Empirical Macroeconometrics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../references.html" rel="next">
<link href="../chapters/12_regularization.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-f555ed0e695c0487cf72966c0b30f9ff.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-ec3f846469679b9e6f6b146d88a0bba5.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/12_regularization.html">Phase 6: Causal Machine Learning</a></li><li class="breadcrumb-item"><a href="../chapters/13_causal_ml.html"><span class="chapter-title">Causal Machine Learning</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Mastering Empirical Macroeconometrics</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/bijoyratanghosh/empirical-macro-curriculum" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Mastering Empirical Macroeconometrics</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Phase 1: Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/01_panel_econometrics.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Panel Data Econometrics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/02_identification.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Identification in Macroeconomics</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Phase 2: Dynamic Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/03_local_projections.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Local Projections</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/04_var_svar.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Vector Autoregressions</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Phase 3: Treatment Effects</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/05_staggered_did.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Staggered Difference-in-Differences</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/06_synthetic_control.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Synthetic Control Methods</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Phase 4: Bayesian Econometrics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/07_bayesian_foundations.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Bayesian Foundations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/08_bayesian_var.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Bayesian Vector Autoregressions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/09_bayesian_panel.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Bayesian Panel Methods</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Phase 5: Structural Macro</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/10_dsge_foundations.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">DSGE Foundations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/11_dsge_estimation.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">DSGE Estimation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Phase 6: Causal Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/12_regularization.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Regularization for Macro</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/13_causal_ml.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Causal Machine Learning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#from-prediction-to-causation" id="toc-from-prediction-to-causation" class="nav-link active" data-scroll-target="#from-prediction-to-causation">From Prediction to Causation</a>
  <ul class="collapse">
  <li><a href="#key-papers" id="toc-key-papers" class="nav-link" data-scroll-target="#key-papers">Key Papers</a></li>
  </ul></li>
  <li><a href="#the-potential-outcomes-framework" id="toc-the-potential-outcomes-framework" class="nav-link" data-scroll-target="#the-potential-outcomes-framework">The Potential Outcomes Framework</a>
  <ul class="collapse">
  <li><a href="#setup" id="toc-setup" class="nav-link" data-scroll-target="#setup">Setup</a></li>
  <li><a href="#treatment-effects-taxonomy" id="toc-treatment-effects-taxonomy" class="nav-link" data-scroll-target="#treatment-effects-taxonomy">Treatment Effects Taxonomy</a></li>
  <li><a href="#the-fundamental-problem-of-causal-inference" id="toc-the-fundamental-problem-of-causal-inference" class="nav-link" data-scroll-target="#the-fundamental-problem-of-causal-inference">The Fundamental Problem of Causal Inference</a></li>
  </ul></li>
  <li><a href="#heterogeneous-treatment-effects" id="toc-heterogeneous-treatment-effects" class="nav-link" data-scroll-target="#heterogeneous-treatment-effects">Heterogeneous Treatment Effects</a>
  <ul class="collapse">
  <li><a href="#why-heterogeneity-matters" id="toc-why-heterogeneity-matters" class="nav-link" data-scroll-target="#why-heterogeneity-matters">Why Heterogeneity Matters</a></li>
  <li><a href="#traditional-approaches-and-their-limitations" id="toc-traditional-approaches-and-their-limitations" class="nav-link" data-scroll-target="#traditional-approaches-and-their-limitations">Traditional Approaches and Their Limitations</a></li>
  </ul></li>
  <li><a href="#causal-forests" id="toc-causal-forests" class="nav-link" data-scroll-target="#causal-forests">Causal Forests</a>
  <ul class="collapse">
  <li><a href="#the-key-idea-wager-athey-2018" id="toc-the-key-idea-wager-athey-2018" class="nav-link" data-scroll-target="#the-key-idea-wager-athey-2018">The Key Idea (Wager &amp; Athey 2018)</a></li>
  <li><a href="#algorithm" id="toc-algorithm" class="nav-link" data-scroll-target="#algorithm">Algorithm</a></li>
  <li><a href="#r-implementation-with-grf" id="toc-r-implementation-with-grf" class="nav-link" data-scroll-target="#r-implementation-with-grf">R Implementation with <code>grf</code></a></li>
  <li><a href="#key-grf-functions" id="toc-key-grf-functions" class="nav-link" data-scroll-target="#key-grf-functions">Key <code>grf</code> Functions</a></li>
  <li><a href="#variable-importance" id="toc-variable-importance" class="nav-link" data-scroll-target="#variable-importance">Variable Importance</a></li>
  <li><a href="#observational-data-pre-estimated-nuisance-functions" id="toc-observational-data-pre-estimated-nuisance-functions" class="nav-link" data-scroll-target="#observational-data-pre-estimated-nuisance-functions">Observational Data: Pre-Estimated Nuisance Functions</a></li>
  </ul></li>
  <li><a href="#doubledebiased-machine-learning" id="toc-doubledebiased-machine-learning" class="nav-link" data-scroll-target="#doubledebiased-machine-learning">Double/Debiased Machine Learning</a>
  <ul class="collapse">
  <li><a href="#the-problem" id="toc-the-problem" class="nav-link" data-scroll-target="#the-problem">The Problem</a></li>
  <li><a href="#the-solution-chernozhukov-et-al.-2018" id="toc-the-solution-chernozhukov-et-al.-2018" class="nav-link" data-scroll-target="#the-solution-chernozhukov-et-al.-2018">The Solution (Chernozhukov et al.&nbsp;2018)</a></li>
  <li><a href="#partially-linear-model" id="toc-partially-linear-model" class="nav-link" data-scroll-target="#partially-linear-model">Partially Linear Model</a></li>
  <li><a href="#the-algorithm" id="toc-the-algorithm" class="nav-link" data-scroll-target="#the-algorithm">The Algorithm</a></li>
  <li><a href="#why-it-works-orthogonality" id="toc-why-it-works-orthogonality" class="nav-link" data-scroll-target="#why-it-works-orthogonality">Why It Works: Orthogonality</a></li>
  <li><a href="#python-implementation-with-doubleml" id="toc-python-implementation-with-doubleml" class="nav-link" data-scroll-target="#python-implementation-with-doubleml">Python Implementation with <code>doubleml</code></a></li>
  <li><a href="#using-the-doubleml-package" id="toc-using-the-doubleml-package" class="nav-link" data-scroll-target="#using-the-doubleml-package">Using the <code>DoubleML</code> Package</a></li>
  <li><a href="#r-implementation" id="toc-r-implementation" class="nav-link" data-scroll-target="#r-implementation">R Implementation</a></li>
  </ul></li>
  <li><a href="#meta-learners" id="toc-meta-learners" class="nav-link" data-scroll-target="#meta-learners">Meta-Learners</a>
  <ul class="collapse">
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#t-learner-two-models" id="toc-t-learner-two-models" class="nav-link" data-scroll-target="#t-learner-two-models">T-Learner (Two Models)</a></li>
  <li><a href="#s-learner-single-model" id="toc-s-learner-single-model" class="nav-link" data-scroll-target="#s-learner-single-model">S-Learner (Single Model)</a></li>
  <li><a href="#x-learner-künzel-et-al.-2019" id="toc-x-learner-künzel-et-al.-2019" class="nav-link" data-scroll-target="#x-learner-künzel-et-al.-2019">X-Learner (Künzel et al.&nbsp;2019)</a></li>
  <li><a href="#comparison" id="toc-comparison" class="nav-link" data-scroll-target="#comparison">Comparison</a></li>
  </ul></li>
  <li><a href="#group-average-treatment-effects-gates" id="toc-group-average-treatment-effects-gates" class="nav-link" data-scroll-target="#group-average-treatment-effects-gates">Group Average Treatment Effects (GATES)</a>
  <ul class="collapse">
  <li><a href="#evaluating-heterogeneity" id="toc-evaluating-heterogeneity" class="nav-link" data-scroll-target="#evaluating-heterogeneity">Evaluating Heterogeneity</a></li>
  <li><a href="#best-linear-predictor-blp" id="toc-best-linear-predictor-blp" class="nav-link" data-scroll-target="#best-linear-predictor-blp">Best Linear Predictor (BLP)</a></li>
  </ul></li>
  <li><a href="#econml-microsofts-causal-ml-toolkit" id="toc-econml-microsofts-causal-ml-toolkit" class="nav-link" data-scroll-target="#econml-microsofts-causal-ml-toolkit">EconML: Microsoft’s Causal ML Toolkit</a>
  <ul class="collapse">
  <li><a href="#overview-1" id="toc-overview-1" class="nav-link" data-scroll-target="#overview-1">Overview</a></li>
  <li><a href="#key-estimators" id="toc-key-estimators" class="nav-link" data-scroll-target="#key-estimators">Key Estimators</a></li>
  <li><a href="#python-implementation" id="toc-python-implementation" class="nav-link" data-scroll-target="#python-implementation">Python Implementation</a></li>
  <li><a href="#unified-api-pattern" id="toc-unified-api-pattern" class="nav-link" data-scroll-target="#unified-api-pattern">Unified API Pattern</a></li>
  </ul></li>
  <li><a href="#applications-in-macroeconomics" id="toc-applications-in-macroeconomics" class="nav-link" data-scroll-target="#applications-in-macroeconomics">Applications in Macroeconomics</a>
  <ul class="collapse">
  <li><a href="#heterogeneous-policy-effects" id="toc-heterogeneous-policy-effects" class="nav-link" data-scroll-target="#heterogeneous-policy-effects">Heterogeneous Policy Effects</a></li>
  <li><a href="#example-cross-country-monetary-transmission" id="toc-example-cross-country-monetary-transmission" class="nav-link" data-scroll-target="#example-cross-country-monetary-transmission">Example: Cross-Country Monetary Transmission</a></li>
  <li><a href="#fiscal-multiplier-heterogeneity" id="toc-fiscal-multiplier-heterogeneity" class="nav-link" data-scroll-target="#fiscal-multiplier-heterogeneity">Fiscal Multiplier Heterogeneity</a></li>
  </ul></li>
  <li><a href="#practical-considerations" id="toc-practical-considerations" class="nav-link" data-scroll-target="#practical-considerations">Practical Considerations</a>
  <ul class="collapse">
  <li><a href="#sample-size-requirements" id="toc-sample-size-requirements" class="nav-link" data-scroll-target="#sample-size-requirements">Sample Size Requirements</a></li>
  <li><a href="#diagnostics" id="toc-diagnostics" class="nav-link" data-scroll-target="#diagnostics">Diagnostics</a>
  <ul class="collapse">
  <li><a href="#overlap-check" id="toc-overlap-check" class="nav-link" data-scroll-target="#overlap-check">Overlap Check</a></li>
  <li><a href="#calibration-test" id="toc-calibration-test" class="nav-link" data-scroll-target="#calibration-test">Calibration Test</a></li>
  <li><a href="#autoc-targeting-quality" id="toc-autoc-targeting-quality" class="nav-link" data-scroll-target="#autoc-targeting-quality">AUTOC (Targeting Quality)</a></li>
  </ul></li>
  <li><a href="#common-pitfalls" id="toc-common-pitfalls" class="nav-link" data-scroll-target="#common-pitfalls">Common Pitfalls</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  <li><a href="#key-references" id="toc-key-references" class="nav-link" data-scroll-target="#key-references">Key References</a>
  <ul class="collapse">
  <li><a href="#foundational" id="toc-foundational" class="nav-link" data-scroll-target="#foundational">Foundational</a></li>
  <li><a href="#extensions" id="toc-extensions" class="nav-link" data-scroll-target="#extensions">Extensions</a></li>
  <li><a href="#resources" id="toc-resources" class="nav-link" data-scroll-target="#resources">Resources</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/bijoyratanghosh/empirical-macro-curriculum/edit/main/chapters/13_causal_ml.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/bijoyratanghosh/empirical-macro-curriculum/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/12_regularization.html">Phase 6: Causal Machine Learning</a></li><li class="breadcrumb-item"><a href="../chapters/13_causal_ml.html"><span class="chapter-title">Causal Machine Learning</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-title">Causal Machine Learning</span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
<p class="subtitle lead">Heterogeneous Treatment Effects, Causal Forests, and Double ML</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># Python setup (run in your Python environment)</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4"></a>np.random.seed(<span class="dv">42</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<section id="from-prediction-to-causation" class="level1 unnumbered">
<h1 class="unnumbered">From Prediction to Causation</h1>
<p>Machine learning excels at <strong>prediction</strong>: minimizing <span class="math inline">\(\mathbb{E}[(Y - \hat{f}(X))^2]\)</span>. But economists care about <strong>causation</strong>: what happens to <span class="math inline">\(Y\)</span> if we <em>intervene</em> on <span class="math inline">\(X\)</span>?</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 41%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Goal</th>
<th>Question</th>
<th>Method</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Prediction</strong></td>
<td>What is <span class="math inline">\(\hat{y}\)</span> given <span class="math inline">\(x\)</span>?</td>
<td>Random forest, neural net, boosting</td>
</tr>
<tr class="even">
<td><strong>Causation</strong></td>
<td>What happens to <span class="math inline">\(y\)</span> if we change <span class="math inline">\(x\)</span>?</td>
<td>Experiments, IV, DiD, RDD</td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>The Causal ML Revolution
</div>
</div>
<div class="callout-body-container callout-body">
<p>Recent methods—causal forests, double ML, meta-learners—combine ML’s flexibility for high-dimensional data with causal inference’s focus on identification <span class="citation" data-cites="athey2019">(<a href="../references.html#ref-athey2019" role="doc-biblioref">Athey and Imbens 2019</a>)</span>. The key insight: use ML for <strong>nuisance parameters</strong> (propensity scores, outcome models) while preserving valid <strong>causal inference</strong>. Key methodological foundations include causal forests <span class="citation" data-cites="wager2018">(<a href="../references.html#ref-wager2018" role="doc-biblioref">Wager and Athey 2018</a>)</span> and double/debiased ML <span class="citation" data-cites="chernozhukov2018">(<a href="../references.html#ref-chernozhukov2018" role="doc-biblioref">Chernozhukov et al. 2018</a>)</span>.</p>
</div>
</div>
<section id="key-papers" class="level2">
<h2 class="anchored" data-anchor-id="key-papers">Key Papers</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 66%">
</colgroup>
<thead>
<tr class="header">
<th>Paper</th>
<th>Contribution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Athey &amp; Imbens (2016)</strong></td>
<td>Recursive partitioning for heterogeneous causal effects</td>
</tr>
<tr class="even">
<td><strong>Wager &amp; Athey (2018)</strong></td>
<td>Causal forests with valid asymptotic inference</td>
</tr>
<tr class="odd">
<td><strong>Chernozhukov et al.&nbsp;(2018)</strong></td>
<td>Double/Debiased ML for high-dimensional controls</td>
</tr>
<tr class="even">
<td><strong>Künzel et al.&nbsp;(2019)</strong></td>
<td>Meta-learners (X-learner) for CATE</td>
</tr>
<tr class="odd">
<td><strong>Athey &amp; Wager (2021)</strong></td>
<td>Policy learning with observational data</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="the-potential-outcomes-framework" class="level1 unnumbered">
<h1 class="unnumbered">The Potential Outcomes Framework</h1>
<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">Setup</h2>
<p>For each unit <span class="math inline">\(i\)</span>:</p>
<ul>
<li><strong>Treatment</strong>: <span class="math inline">\(W_i \in \{0, 1\}\)</span></li>
<li><strong>Potential outcomes</strong>: <span class="math inline">\(Y_i(0), Y_i(1)\)</span> — what would happen under control/treatment</li>
<li><strong>Observed outcome</strong>: <span class="math inline">\(Y_i = W_i \cdot Y_i(1) + (1 - W_i) \cdot Y_i(0)\)</span></li>
<li><strong>Covariates</strong>: <span class="math inline">\(X_i\)</span> (pre-treatment characteristics)</li>
</ul>
</section>
<section id="treatment-effects-taxonomy" class="level2">
<h2 class="anchored" data-anchor-id="treatment-effects-taxonomy">Treatment Effects Taxonomy</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 26%">
<col style="width: 31%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Estimand</th>
<th>Definition</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>ITE</strong></td>
<td><span class="math inline">\(\tau_i = Y_i(1) - Y_i(0)\)</span></td>
<td>Individual effect (unobservable)</td>
</tr>
<tr class="even">
<td><strong>CATE</strong></td>
<td><span class="math inline">\(\tau(x) = \mathbb{E}[Y(1) - Y(0) \mid X = x]\)</span></td>
<td>Conditional average effect</td>
</tr>
<tr class="odd">
<td><strong>ATE</strong></td>
<td><span class="math inline">\(\mathbb{E}[\tau_i]\)</span></td>
<td>Average treatment effect</td>
</tr>
<tr class="even">
<td><strong>ATT</strong></td>
<td><span class="math inline">\(\mathbb{E}[\tau_i \mid W_i = 1]\)</span></td>
<td>Effect on the treated</td>
</tr>
</tbody>
</table>
</section>
<section id="the-fundamental-problem-of-causal-inference" class="level2">
<h2 class="anchored" data-anchor-id="the-fundamental-problem-of-causal-inference">The Fundamental Problem of Causal Inference</h2>
<p>We observe either <span class="math inline">\(Y_i(1)\)</span> OR <span class="math inline">\(Y_i(0)\)</span>, never both. The individual treatment effect <span class="math inline">\(\tau_i\)</span> is <strong>fundamentally unidentifiable</strong>.</p>
<p><strong>Solution</strong>: Under <strong>unconfoundedness</strong> (selection on observables): <span class="math display">\[
(Y_i(0), Y_i(1)) \perp\!\!\!\perp W_i \mid X_i
\]</span></p>
<p>Plus <strong>overlap</strong> (positivity): <span class="math inline">\(0 &lt; P(W_i = 1 \mid X_i = x) &lt; 1\)</span> for all <span class="math inline">\(x\)</span>.</p>
</section>
</section>
<section id="heterogeneous-treatment-effects" class="level1 unnumbered">
<h1 class="unnumbered">Heterogeneous Treatment Effects</h1>
<section id="why-heterogeneity-matters" class="level2">
<h2 class="anchored" data-anchor-id="why-heterogeneity-matters">Why Heterogeneity Matters</h2>
<p>The ATE <span class="math inline">\(= 2\)</span> could mask:</p>
<ul>
<li>Subgroup A: <span class="math inline">\(\tau = 5\)</span> (strong benefit)</li>
<li>Subgroup B: <span class="math inline">\(\tau = -1\)</span> (harm)</li>
</ul>
<p>Understanding heterogeneity enables:</p>
<ol type="1">
<li><strong>Targeting</strong>: Treat those who benefit most</li>
<li><strong>Mechanism identification</strong>: What drives variation?</li>
<li><strong>Policy optimization</strong>: Maximize welfare under constraints</li>
</ol>
<div class="cell" data-layout-align="center">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># Simulate heterogeneous effects</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>X1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb2-4"><a href="#cb2-4"></a>X2 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb2-5"><a href="#cb2-5"></a></span>
<span id="cb2-6"><a href="#cb2-6"></a><span class="co"># Treatment effect depends on X1</span></span>
<span id="cb2-7"><a href="#cb2-7"></a>tau_true <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">+</span> <span class="fl">1.5</span> <span class="sc">*</span> X1</span>
<span id="cb2-8"><a href="#cb2-8"></a></span>
<span id="cb2-9"><a href="#cb2-9"></a><span class="co"># Treatment assignment (randomized)</span></span>
<span id="cb2-10"><a href="#cb2-10"></a>W <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fl">0.5</span>)</span>
<span id="cb2-11"><a href="#cb2-11"></a></span>
<span id="cb2-12"><a href="#cb2-12"></a><span class="co"># Potential outcomes</span></span>
<span id="cb2-13"><a href="#cb2-13"></a>Y0 <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fl">0.5</span> <span class="sc">*</span> X1 <span class="sc">+</span> <span class="fl">0.3</span> <span class="sc">*</span> X2 <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb2-14"><a href="#cb2-14"></a>Y1 <span class="ot">&lt;-</span> Y0 <span class="sc">+</span> tau_true</span>
<span id="cb2-15"><a href="#cb2-15"></a>Y <span class="ot">&lt;-</span> W <span class="sc">*</span> Y1 <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> W) <span class="sc">*</span> Y0</span>
<span id="cb2-16"><a href="#cb2-16"></a></span>
<span id="cb2-17"><a href="#cb2-17"></a><span class="co"># Create data frame</span></span>
<span id="cb2-18"><a href="#cb2-18"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">Y =</span> Y, <span class="at">W =</span> W, <span class="at">X1 =</span> X1, <span class="at">X2 =</span> X2, <span class="at">tau_true =</span> tau_true)</span>
<span id="cb2-19"><a href="#cb2-19"></a></span>
<span id="cb2-20"><a href="#cb2-20"></a><span class="co"># Show heterogeneity</span></span>
<span id="cb2-21"><a href="#cb2-21"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> X1, <span class="at">y =</span> tau_true)) <span class="sc">+</span></span>
<span id="cb2-22"><a href="#cb2-22"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">color =</span> <span class="st">"#3498db"</span>) <span class="sc">+</span></span>
<span id="cb2-23"><a href="#cb2-23"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">color =</span> <span class="st">"#e74c3c"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb2-24"><a href="#cb2-24"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">mean</span>(tau_true), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"#2ecc71"</span>) <span class="sc">+</span></span>
<span id="cb2-25"><a href="#cb2-25"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">2</span>, <span class="at">y =</span> <span class="fu">mean</span>(tau_true) <span class="sc">+</span> <span class="fl">0.3</span>, <span class="at">label =</span> <span class="st">"ATE"</span>, <span class="at">color =</span> <span class="st">"#2ecc71"</span>) <span class="sc">+</span></span>
<span id="cb2-26"><a href="#cb2-26"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"True Treatment Effect Varies with X₁"</span>,</span>
<span id="cb2-27"><a href="#cb2-27"></a>       <span class="at">subtitle =</span> <span class="st">"ATE masks substantial heterogeneity"</span>,</span>
<span id="cb2-28"><a href="#cb2-28"></a>       <span class="at">x =</span> <span class="fu">expression</span>(X[<span class="dv">1</span>]), <span class="at">y =</span> <span class="st">"True Treatment Effect τ(x)"</span>) <span class="sc">+</span></span>
<span id="cb2-29"><a href="#cb2-29"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13_causal_ml_files/figure-html/heterogeneity-demo-1.png" class="img-fluid figure-img" width="960"></p>
<figcaption>Treatment effect heterogeneity: τ(x) = 2 + 1.5X₁</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="traditional-approaches-and-their-limitations" class="level2">
<h2 class="anchored" data-anchor-id="traditional-approaches-and-their-limitations">Traditional Approaches and Their Limitations</h2>
<p><strong>Subgroup analysis</strong>: Pre-specify groups, estimate effects within each.</p>
<ul>
<li>Problem: Many possible subgroups → multiple testing</li>
<li>Problem: Boundaries are arbitrary</li>
</ul>
<p><strong>Interaction terms</strong>: <span class="math inline">\(Y = \alpha + \tau W + \gamma W \cdot X + \beta X + \varepsilon\)</span></p>
<ul>
<li>Problem: Must specify functional form</li>
<li>Problem: Doesn’t scale to many <span class="math inline">\(X\)</span></li>
</ul>
<p><strong>Causal ML</strong>: Learn <span class="math inline">\(\tau(x)\)</span> flexibly from data with valid inference.</p>
</section>
</section>
<section id="causal-forests" class="level1 unnumbered">
<h1 class="unnumbered">Causal Forests</h1>
<section id="the-key-idea-wager-athey-2018" class="level2">
<h2 class="anchored" data-anchor-id="the-key-idea-wager-athey-2018">The Key Idea (Wager &amp; Athey 2018)</h2>
<p>Adapt random forests from predicting <span class="math inline">\(\mathbb{E}[Y|X]\)</span> to predicting <span class="math inline">\(\tau(x) = \mathbb{E}[Y(1) - Y(0)|X=x]\)</span>.</p>
<p><strong>Key innovations</strong>:</p>
<ol type="1">
<li><strong>Honest splitting</strong>: Separate samples for tree structure vs.&nbsp;leaf estimation</li>
<li><strong>Heterogeneity-maximizing splits</strong>: Split to maximize treatment effect variation</li>
<li><strong>Valid inference</strong>: Asymptotic normality of estimates</li>
</ol>
</section>
<section id="algorithm" class="level2">
<h2 class="anchored" data-anchor-id="algorithm">Algorithm</h2>
<p>For each tree <span class="math inline">\(b = 1, \ldots, B\)</span>:</p>
<ol type="1">
<li><strong>Subsample</strong> data into tree-building (<span class="math inline">\(\mathcal{I}_1\)</span>) and estimation (<span class="math inline">\(\mathcal{I}_2\)</span>) sets</li>
<li><strong>Build tree</strong> on <span class="math inline">\(\mathcal{I}_1\)</span>: at each node, find split maximizing heterogeneity</li>
<li><strong>Estimate leaf effects</strong> using <span class="math inline">\(\mathcal{I}_2\)</span> only (honesty)</li>
<li><strong>Aggregate</strong>: <span class="math inline">\(\hat{\tau}(x) = \frac{1}{B} \sum_b \hat{\tau}_b(x)\)</span></li>
</ol>
</section>
<section id="r-implementation-with-grf" class="level2">
<h2 class="anchored" data-anchor-id="r-implementation-with-grf">R Implementation with <code>grf</code></h2>
<div class="cell" data-layout-align="center">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="fu">library</span>(grf)</span>
<span id="cb3-2"><a href="#cb3-2"></a></span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="co"># Prepare data</span></span>
<span id="cb3-4"><a href="#cb3-4"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(X1, X2)</span>
<span id="cb3-5"><a href="#cb3-5"></a></span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="co"># Fit causal forest</span></span>
<span id="cb3-7"><a href="#cb3-7"></a>cf <span class="ot">&lt;-</span> <span class="fu">causal_forest</span>(</span>
<span id="cb3-8"><a href="#cb3-8"></a>  <span class="at">X =</span> X,</span>
<span id="cb3-9"><a href="#cb3-9"></a>  <span class="at">Y =</span> Y,</span>
<span id="cb3-10"><a href="#cb3-10"></a>  <span class="at">W =</span> W,</span>
<span id="cb3-11"><a href="#cb3-11"></a>  <span class="at">num.trees =</span> <span class="dv">2000</span>,</span>
<span id="cb3-12"><a href="#cb3-12"></a>  <span class="at">honesty =</span> <span class="cn">TRUE</span>,           <span class="co"># honest splitting (default)</span></span>
<span id="cb3-13"><a href="#cb3-13"></a>  <span class="at">tune.parameters =</span> <span class="st">"all"</span>   <span class="co"># automatic hyperparameter tuning</span></span>
<span id="cb3-14"><a href="#cb3-14"></a>)</span>
<span id="cb3-15"><a href="#cb3-15"></a></span>
<span id="cb3-16"><a href="#cb3-16"></a><span class="co"># Predict treatment effects</span></span>
<span id="cb3-17"><a href="#cb3-17"></a>tau_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(cf)<span class="sc">$</span>predictions</span>
<span id="cb3-18"><a href="#cb3-18"></a></span>
<span id="cb3-19"><a href="#cb3-19"></a><span class="co"># Compare to truth</span></span>
<span id="cb3-20"><a href="#cb3-20"></a>comparison_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb3-21"><a href="#cb3-21"></a>  <span class="at">true =</span> tau_true,</span>
<span id="cb3-22"><a href="#cb3-22"></a>  <span class="at">estimated =</span> tau_hat,</span>
<span id="cb3-23"><a href="#cb3-23"></a>  <span class="at">X1 =</span> X1</span>
<span id="cb3-24"><a href="#cb3-24"></a>)</span>
<span id="cb3-25"><a href="#cb3-25"></a></span>
<span id="cb3-26"><a href="#cb3-26"></a><span class="co"># Scatter: estimated vs true</span></span>
<span id="cb3-27"><a href="#cb3-27"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(comparison_df, <span class="fu">aes</span>(<span class="at">x =</span> true, <span class="at">y =</span> estimated)) <span class="sc">+</span></span>
<span id="cb3-28"><a href="#cb3-28"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">color =</span> <span class="st">"#3498db"</span>) <span class="sc">+</span></span>
<span id="cb3-29"><a href="#cb3-29"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"#e74c3c"</span>) <span class="sc">+</span></span>
<span id="cb3-30"><a href="#cb3-30"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Estimated vs True CATE"</span>,</span>
<span id="cb3-31"><a href="#cb3-31"></a>       <span class="at">x =</span> <span class="st">"True τ(x)"</span>, <span class="at">y =</span> <span class="st">"Estimated τ̂(x)"</span>) <span class="sc">+</span></span>
<span id="cb3-32"><a href="#cb3-32"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb3-33"><a href="#cb3-33"></a></span>
<span id="cb3-34"><a href="#cb3-34"></a><span class="co"># By X1</span></span>
<span id="cb3-35"><a href="#cb3-35"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(comparison_df, <span class="fu">aes</span>(<span class="at">x =</span> X1)) <span class="sc">+</span></span>
<span id="cb3-36"><a href="#cb3-36"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> true), <span class="at">alpha =</span> <span class="fl">0.2</span>, <span class="at">color =</span> <span class="st">"#2ecc71"</span>) <span class="sc">+</span></span>
<span id="cb3-37"><a href="#cb3-37"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> estimated), <span class="at">alpha =</span> <span class="fl">0.2</span>, <span class="at">color =</span> <span class="st">"#3498db"</span>) <span class="sc">+</span></span>
<span id="cb3-38"><a href="#cb3-38"></a>  <span class="fu">geom_smooth</span>(<span class="fu">aes</span>(<span class="at">y =</span> estimated), <span class="at">method =</span> <span class="st">"loess"</span>, <span class="at">color =</span> <span class="st">"#e74c3c"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb3-39"><a href="#cb3-39"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"CATE by X₁"</span>,</span>
<span id="cb3-40"><a href="#cb3-40"></a>       <span class="at">subtitle =</span> <span class="st">"Green = true, Blue = estimated"</span>,</span>
<span id="cb3-41"><a href="#cb3-41"></a>       <span class="at">x =</span> <span class="fu">expression</span>(X[<span class="dv">1</span>]), <span class="at">y =</span> <span class="st">"Treatment Effect"</span>) <span class="sc">+</span></span>
<span id="cb3-42"><a href="#cb3-42"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb3-43"><a href="#cb3-43"></a></span>
<span id="cb3-44"><a href="#cb3-44"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(p1, p2, <span class="at">ncol =</span> <span class="dv">2</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13_causal_ml_files/figure-html/causal-forest-1.png" class="img-fluid figure-img" width="960"></p>
<figcaption>Causal forest recovers heterogeneous treatment effects</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="key-grf-functions" class="level2">
<h2 class="anchored" data-anchor-id="key-grf-functions">Key <code>grf</code> Functions</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a><span class="fu">library</span>(grf)</span>
<span id="cb4-2"><a href="#cb4-2"></a></span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="co"># Fit causal forest</span></span>
<span id="cb4-4"><a href="#cb4-4"></a>cf <span class="ot">&lt;-</span> <span class="fu">causal_forest</span>(X, Y, W, <span class="at">num.trees =</span> <span class="dv">2000</span>)</span>
<span id="cb4-5"><a href="#cb4-5"></a></span>
<span id="cb4-6"><a href="#cb4-6"></a><span class="co"># Point predictions</span></span>
<span id="cb4-7"><a href="#cb4-7"></a>tau_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(cf)<span class="sc">$</span>predictions</span>
<span id="cb4-8"><a href="#cb4-8"></a></span>
<span id="cb4-9"><a href="#cb4-9"></a><span class="co"># Predictions with variance (for CIs)</span></span>
<span id="cb4-10"><a href="#cb4-10"></a>tau_ci <span class="ot">&lt;-</span> <span class="fu">predict</span>(cf, <span class="at">estimate.variance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb4-11"><a href="#cb4-11"></a>lower <span class="ot">&lt;-</span> tau_ci<span class="sc">$</span>predictions <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> <span class="fu">sqrt</span>(tau_ci<span class="sc">$</span>variance.estimates)</span>
<span id="cb4-12"><a href="#cb4-12"></a>upper <span class="ot">&lt;-</span> tau_ci<span class="sc">$</span>predictions <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> <span class="fu">sqrt</span>(tau_ci<span class="sc">$</span>variance.estimates)</span>
<span id="cb4-13"><a href="#cb4-13"></a></span>
<span id="cb4-14"><a href="#cb4-14"></a><span class="co"># Average treatment effect with SE</span></span>
<span id="cb4-15"><a href="#cb4-15"></a>ate <span class="ot">&lt;-</span> <span class="fu">average_treatment_effect</span>(cf, <span class="at">target.sample =</span> <span class="st">"all"</span>)</span>
<span id="cb4-16"><a href="#cb4-16"></a><span class="fu">cat</span>(<span class="st">"ATE:"</span>, ate[<span class="dv">1</span>], <span class="st">"SE:"</span>, ate[<span class="dv">2</span>], <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb4-17"><a href="#cb4-17"></a></span>
<span id="cb4-18"><a href="#cb4-18"></a><span class="co"># ATT</span></span>
<span id="cb4-19"><a href="#cb4-19"></a>att <span class="ot">&lt;-</span> <span class="fu">average_treatment_effect</span>(cf, <span class="at">target.sample =</span> <span class="st">"treated"</span>)</span>
<span id="cb4-20"><a href="#cb4-20"></a></span>
<span id="cb4-21"><a href="#cb4-21"></a><span class="co"># Variable importance: which X drive heterogeneity?</span></span>
<span id="cb4-22"><a href="#cb4-22"></a>vi <span class="ot">&lt;-</span> <span class="fu">variable_importance</span>(cf)</span>
<span id="cb4-23"><a href="#cb4-23"></a></span>
<span id="cb4-24"><a href="#cb4-24"></a><span class="co"># Best linear projection: linear approximation of τ(x)</span></span>
<span id="cb4-25"><a href="#cb4-25"></a>blp <span class="ot">&lt;-</span> <span class="fu">best_linear_projection</span>(cf, X)</span>
<span id="cb4-26"><a href="#cb4-26"></a></span>
<span id="cb4-27"><a href="#cb4-27"></a><span class="co"># Calibration test: is there heterogeneity?</span></span>
<span id="cb4-28"><a href="#cb4-28"></a><span class="fu">test_calibration</span>(cf)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="variable-importance" class="level2">
<h2 class="anchored" data-anchor-id="variable-importance">Variable Importance</h2>
<p>Which covariates drive treatment effect heterogeneity?</p>
<div class="cell" data-layout-align="center">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="co"># Variable importance</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>vi <span class="ot">&lt;-</span> <span class="fu">variable_importance</span>(cf)</span>
<span id="cb5-3"><a href="#cb5-3"></a>vi_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb5-4"><a href="#cb5-4"></a>  <span class="at">variable =</span> <span class="fu">c</span>(<span class="st">"X1"</span>, <span class="st">"X2"</span>),</span>
<span id="cb5-5"><a href="#cb5-5"></a>  <span class="at">importance =</span> vi</span>
<span id="cb5-6"><a href="#cb5-6"></a>)</span>
<span id="cb5-7"><a href="#cb5-7"></a></span>
<span id="cb5-8"><a href="#cb5-8"></a><span class="fu">ggplot</span>(vi_df, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(variable, importance), <span class="at">y =</span> importance)) <span class="sc">+</span></span>
<span id="cb5-9"><a href="#cb5-9"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="at">fill =</span> <span class="st">"#3498db"</span>) <span class="sc">+</span></span>
<span id="cb5-10"><a href="#cb5-10"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb5-11"><a href="#cb5-11"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Variable Importance for Treatment Heterogeneity"</span>,</span>
<span id="cb5-12"><a href="#cb5-12"></a>       <span class="at">subtitle =</span> <span class="st">"X₁ drives heterogeneity (as designed)"</span>,</span>
<span id="cb5-13"><a href="#cb5-13"></a>       <span class="at">x =</span> <span class="cn">NULL</span>, <span class="at">y =</span> <span class="st">"Importance"</span>) <span class="sc">+</span></span>
<span id="cb5-14"><a href="#cb5-14"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13_causal_ml_files/figure-html/variable-importance-1.png" class="img-fluid figure-img" width="960"></p>
<figcaption>Variable importance identifies X₁ as driver of heterogeneity</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="observational-data-pre-estimated-nuisance-functions" class="level2">
<h2 class="anchored" data-anchor-id="observational-data-pre-estimated-nuisance-functions">Observational Data: Pre-Estimated Nuisance Functions</h2>
<p>For observational studies, pre-fit propensity and outcome models:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a><span class="co"># Pre-fit nuisance models (recommended for observational data)</span></span>
<span id="cb6-2"><a href="#cb6-2"></a>W.hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(<span class="fu">regression_forest</span>(X, W))<span class="sc">$</span>predictions  <span class="co"># propensity</span></span>
<span id="cb6-3"><a href="#cb6-3"></a>Y.hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(<span class="fu">regression_forest</span>(X, Y))<span class="sc">$</span>predictions  <span class="co"># outcome</span></span>
<span id="cb6-4"><a href="#cb6-4"></a></span>
<span id="cb6-5"><a href="#cb6-5"></a><span class="co"># Causal forest with pre-estimated nuisance</span></span>
<span id="cb6-6"><a href="#cb6-6"></a>cf_obs <span class="ot">&lt;-</span> <span class="fu">causal_forest</span>(X, Y, W, <span class="at">W.hat =</span> W.hat, <span class="at">Y.hat =</span> Y.hat)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
</section>
<section id="doubledebiased-machine-learning" class="level1 unnumbered">
<h1 class="unnumbered">Double/Debiased Machine Learning</h1>
<section id="the-problem" class="level2">
<h2 class="anchored" data-anchor-id="the-problem">The Problem</h2>
<p>When using ML for nuisance parameters (propensity score, outcome model), regularization introduces bias that <strong>invalidates standard inference</strong>.</p>
<p><strong>Example</strong>: LASSO shrinks coefficients → biased treatment effect → invalid t-statistics.</p>
</section>
<section id="the-solution-chernozhukov-et-al.-2018" class="level2">
<h2 class="anchored" data-anchor-id="the-solution-chernozhukov-et-al.-2018">The Solution (Chernozhukov et al.&nbsp;2018)</h2>
<p>Two key ingredients:</p>
<ol type="1">
<li><strong>Cross-fitting</strong>: Train ML on fold <span class="math inline">\(-k\)</span>, predict on fold <span class="math inline">\(k\)</span></li>
<li><strong>Neyman orthogonality</strong>: Use score function robust to nuisance estimation error</li>
</ol>
</section>
<section id="partially-linear-model" class="level2">
<h2 class="anchored" data-anchor-id="partially-linear-model">Partially Linear Model</h2>
<p><span class="math display">\[
Y = \theta D + g(X) + U, \quad \mathbb{E}[U|X,D] = 0
\]</span> <span class="math display">\[
D = m(X) + V, \quad \mathbb{E}[V|X] = 0
\]</span></p>
<p><strong>Target</strong>: <span class="math inline">\(\theta\)</span> (treatment effect)</p>
<p><strong>Nuisance</strong>: <span class="math inline">\(g(X)\)</span> (outcome confounding), <span class="math inline">\(m(X)\)</span> (propensity/treatment model)</p>
</section>
<section id="the-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="the-algorithm">The Algorithm</h2>
<ol type="1">
<li>Split data into <span class="math inline">\(K\)</span> folds (typically <span class="math inline">\(K = 5\)</span>)</li>
<li>For each fold <span class="math inline">\(k\)</span>:
<ul>
<li>Train <span class="math inline">\(\hat{g}_{-k}(X)\)</span> and <span class="math inline">\(\hat{m}_{-k}(X)\)</span> on all other folds</li>
<li>Compute residuals on fold <span class="math inline">\(k\)</span>:
<ul>
<li><span class="math inline">\(\tilde{Y}_i = Y_i - \hat{g}_{-k}(X_i)\)</span></li>
<li><span class="math inline">\(\tilde{D}_i = D_i - \hat{m}_{-k}(X_i)\)</span></li>
</ul></li>
</ul></li>
<li>Estimate: <span class="math inline">\(\hat{\theta} = \frac{\sum_i \tilde{D}_i \tilde{Y}_i}{\sum_i \tilde{D}_i^2}\)</span></li>
<li>Standard error: standard OLS formula on residualized data</li>
</ol>
</section>
<section id="why-it-works-orthogonality" class="level2">
<h2 class="anchored" data-anchor-id="why-it-works-orthogonality">Why It Works: Orthogonality</h2>
<p>The <strong>orthogonal moment condition</strong>: <span class="math display">\[
\psi(W; \theta, \eta) = (Y - g(X) - \theta D)(D - m(X))
\]</span></p>
<p>has the property that small errors in <span class="math inline">\(\hat{g}, \hat{m}\)</span> don’t bias <span class="math inline">\(\hat{\theta}\)</span>: <span class="math display">\[
\frac{\partial}{\partial \eta} \mathbb{E}[\psi(W; \theta_0, \eta)] \bigg|_{\eta = \eta_0} = 0
\]</span></p>
</section>
<section id="python-implementation-with-doubleml" class="level2">
<h2 class="anchored" data-anchor-id="python-implementation-with-doubleml">Python Implementation with <code>doubleml</code></h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># Double ML estimation in Python</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_predict</span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="im">import</span> warnings</span>
<span id="cb7-5"><a href="#cb7-5"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb7-6"><a href="#cb7-6"></a></span>
<span id="cb7-7"><a href="#cb7-7"></a><span class="co"># Simulate data</span></span>
<span id="cb7-8"><a href="#cb7-8"></a>n <span class="op">=</span> <span class="dv">2000</span></span>
<span id="cb7-9"><a href="#cb7-9"></a>p <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb7-10"><a href="#cb7-10"></a>X <span class="op">=</span> np.random.randn(n, p)</span>
<span id="cb7-11"><a href="#cb7-11"></a>theta_true <span class="op">=</span> <span class="fl">0.5</span>  <span class="co"># true treatment effect</span></span>
<span id="cb7-12"><a href="#cb7-12"></a>D <span class="op">=</span> X[:, <span class="dv">0</span>] <span class="op">+</span> <span class="fl">0.5</span> <span class="op">*</span> X[:, <span class="dv">1</span>] <span class="op">+</span> np.random.randn(n)  <span class="co"># treatment depends on X</span></span>
<span id="cb7-13"><a href="#cb7-13"></a>Y <span class="op">=</span> theta_true <span class="op">*</span> D <span class="op">+</span> X[:, <span class="dv">0</span>] <span class="op">+</span> X[:, <span class="dv">1</span>] <span class="op">+</span> np.random.randn(n)  <span class="co"># outcome</span></span>
<span id="cb7-14"><a href="#cb7-14"></a></span>
<span id="cb7-15"><a href="#cb7-15"></a><span class="co"># Manual Double ML</span></span>
<span id="cb7-16"><a href="#cb7-16"></a><span class="kw">def</span> double_ml_plr(Y, D, X, K<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb7-17"><a href="#cb7-17"></a>    <span class="co">"""</span></span>
<span id="cb7-18"><a href="#cb7-18"></a><span class="co">    Double ML for Partially Linear Regression</span></span>
<span id="cb7-19"><a href="#cb7-19"></a><span class="co">    Y = theta * D + g(X) + U</span></span>
<span id="cb7-20"><a href="#cb7-20"></a><span class="co">    D = m(X) + V</span></span>
<span id="cb7-21"><a href="#cb7-21"></a><span class="co">    """</span></span>
<span id="cb7-22"><a href="#cb7-22"></a>    n <span class="op">=</span> <span class="bu">len</span>(Y)</span>
<span id="cb7-23"><a href="#cb7-23"></a></span>
<span id="cb7-24"><a href="#cb7-24"></a>    <span class="co"># Cross-fitted predictions</span></span>
<span id="cb7-25"><a href="#cb7-25"></a>    g_hat <span class="op">=</span> cross_val_predict(</span>
<span id="cb7-26"><a href="#cb7-26"></a>        RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, max_depth<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>),</span>
<span id="cb7-27"><a href="#cb7-27"></a>        X, Y, cv<span class="op">=</span>K</span>
<span id="cb7-28"><a href="#cb7-28"></a>    )</span>
<span id="cb7-29"><a href="#cb7-29"></a>    m_hat <span class="op">=</span> cross_val_predict(</span>
<span id="cb7-30"><a href="#cb7-30"></a>        RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, max_depth<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>),</span>
<span id="cb7-31"><a href="#cb7-31"></a>        X, D, cv<span class="op">=</span>K</span>
<span id="cb7-32"><a href="#cb7-32"></a>    )</span>
<span id="cb7-33"><a href="#cb7-33"></a></span>
<span id="cb7-34"><a href="#cb7-34"></a>    <span class="co"># Residualize</span></span>
<span id="cb7-35"><a href="#cb7-35"></a>    Y_tilde <span class="op">=</span> Y <span class="op">-</span> g_hat</span>
<span id="cb7-36"><a href="#cb7-36"></a>    D_tilde <span class="op">=</span> D <span class="op">-</span> m_hat</span>
<span id="cb7-37"><a href="#cb7-37"></a></span>
<span id="cb7-38"><a href="#cb7-38"></a>    <span class="co"># Estimate theta</span></span>
<span id="cb7-39"><a href="#cb7-39"></a>    theta_hat <span class="op">=</span> np.<span class="bu">sum</span>(D_tilde <span class="op">*</span> Y_tilde) <span class="op">/</span> np.<span class="bu">sum</span>(D_tilde <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb7-40"><a href="#cb7-40"></a></span>
<span id="cb7-41"><a href="#cb7-41"></a>    <span class="co"># Standard error</span></span>
<span id="cb7-42"><a href="#cb7-42"></a>    residuals <span class="op">=</span> Y_tilde <span class="op">-</span> theta_hat <span class="op">*</span> D_tilde</span>
<span id="cb7-43"><a href="#cb7-43"></a>    se_hat <span class="op">=</span> np.sqrt(np.<span class="bu">sum</span>(residuals <span class="op">**</span> <span class="dv">2</span> <span class="op">*</span> D_tilde <span class="op">**</span> <span class="dv">2</span>) <span class="op">/</span> (np.<span class="bu">sum</span>(D_tilde <span class="op">**</span> <span class="dv">2</span>) <span class="op">**</span> <span class="dv">2</span>))</span>
<span id="cb7-44"><a href="#cb7-44"></a></span>
<span id="cb7-45"><a href="#cb7-45"></a>    <span class="cf">return</span> {</span>
<span id="cb7-46"><a href="#cb7-46"></a>        <span class="st">'estimate'</span>: theta_hat,</span>
<span id="cb7-47"><a href="#cb7-47"></a>        <span class="st">'se'</span>: se_hat,</span>
<span id="cb7-48"><a href="#cb7-48"></a>        <span class="st">'ci_lower'</span>: theta_hat <span class="op">-</span> <span class="fl">1.96</span> <span class="op">*</span> se_hat,</span>
<span id="cb7-49"><a href="#cb7-49"></a>        <span class="st">'ci_upper'</span>: theta_hat <span class="op">+</span> <span class="fl">1.96</span> <span class="op">*</span> se_hat</span>
<span id="cb7-50"><a href="#cb7-50"></a>    }</span>
<span id="cb7-51"><a href="#cb7-51"></a></span>
<span id="cb7-52"><a href="#cb7-52"></a><span class="co"># Run Double ML</span></span>
<span id="cb7-53"><a href="#cb7-53"></a>result <span class="op">=</span> double_ml_plr(Y, D, X)</span>
<span id="cb7-54"><a href="#cb7-54"></a></span>
<span id="cb7-55"><a href="#cb7-55"></a><span class="bu">print</span>(<span class="ss">f"True θ: </span><span class="sc">{</span>theta_true<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-56"><a href="#cb7-56"></a><span class="bu">print</span>(<span class="ss">f"Double ML estimate: </span><span class="sc">{</span>result[<span class="st">'estimate'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb7-57"><a href="#cb7-57"></a><span class="bu">print</span>(<span class="ss">f"Standard error: </span><span class="sc">{</span>result[<span class="st">'se'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb7-58"><a href="#cb7-58"></a><span class="bu">print</span>(<span class="ss">f"95% CI: [</span><span class="sc">{</span>result[<span class="st">'ci_lower'</span>]<span class="sc">:.4f}</span><span class="ss">, </span><span class="sc">{</span>result[<span class="st">'ci_upper'</span>]<span class="sc">:.4f}</span><span class="ss">]"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="using-the-doubleml-package" class="level2">
<h2 class="anchored" data-anchor-id="using-the-doubleml-package">Using the <code>DoubleML</code> Package</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a><span class="im">from</span> doubleml <span class="im">import</span> DoubleMLPLR, DoubleMLData</span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb8-3"><a href="#cb8-3"></a></span>
<span id="cb8-4"><a href="#cb8-4"></a><span class="co"># Create data object</span></span>
<span id="cb8-5"><a href="#cb8-5"></a>df <span class="op">=</span> pd.DataFrame(X, columns<span class="op">=</span>[<span class="ss">f'X</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(p)])</span>
<span id="cb8-6"><a href="#cb8-6"></a>df[<span class="st">'Y'</span>] <span class="op">=</span> Y</span>
<span id="cb8-7"><a href="#cb8-7"></a>df[<span class="st">'D'</span>] <span class="op">=</span> D</span>
<span id="cb8-8"><a href="#cb8-8"></a></span>
<span id="cb8-9"><a href="#cb8-9"></a>dml_data <span class="op">=</span> DoubleMLData(</span>
<span id="cb8-10"><a href="#cb8-10"></a>    df, y_col<span class="op">=</span><span class="st">'Y'</span>, d_cols<span class="op">=</span><span class="st">'D'</span>,</span>
<span id="cb8-11"><a href="#cb8-11"></a>    x_cols<span class="op">=</span>[<span class="ss">f'X</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(p)]</span>
<span id="cb8-12"><a href="#cb8-12"></a>)</span>
<span id="cb8-13"><a href="#cb8-13"></a></span>
<span id="cb8-14"><a href="#cb8-14"></a><span class="co"># Specify learners</span></span>
<span id="cb8-15"><a href="#cb8-15"></a>ml_l <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">500</span>, max_depth<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb8-16"><a href="#cb8-16"></a>ml_m <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">500</span>, max_depth<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb8-17"><a href="#cb8-17"></a></span>
<span id="cb8-18"><a href="#cb8-18"></a><span class="co"># Fit</span></span>
<span id="cb8-19"><a href="#cb8-19"></a>dml_plr <span class="op">=</span> DoubleMLPLR(dml_data, ml_l, ml_m, n_folds<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb8-20"><a href="#cb8-20"></a>dml_plr.fit()</span>
<span id="cb8-21"><a href="#cb8-21"></a><span class="bu">print</span>(dml_plr.summary)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="r-implementation" class="level2">
<h2 class="anchored" data-anchor-id="r-implementation">R Implementation</h2>
<div class="cell" data-layout-align="center">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a><span class="co"># Manual Double ML for ATE (binary treatment)</span></span>
<span id="cb9-2"><a href="#cb9-2"></a>double_ml_ate <span class="ot">&lt;-</span> <span class="cf">function</span>(Y, W, X, <span class="at">K =</span> <span class="dv">5</span>) {</span>
<span id="cb9-3"><a href="#cb9-3"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(Y)</span>
<span id="cb9-4"><a href="#cb9-4"></a>  folds <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span>K, <span class="at">length.out =</span> n))</span>
<span id="cb9-5"><a href="#cb9-5"></a></span>
<span id="cb9-6"><a href="#cb9-6"></a>  psi <span class="ot">&lt;-</span> <span class="fu">numeric</span>(n)</span>
<span id="cb9-7"><a href="#cb9-7"></a></span>
<span id="cb9-8"><a href="#cb9-8"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>K) {</span>
<span id="cb9-9"><a href="#cb9-9"></a>    train_idx <span class="ot">&lt;-</span> folds <span class="sc">!=</span> k</span>
<span id="cb9-10"><a href="#cb9-10"></a>    test_idx <span class="ot">&lt;-</span> folds <span class="sc">==</span> k</span>
<span id="cb9-11"><a href="#cb9-11"></a></span>
<span id="cb9-12"><a href="#cb9-12"></a>    <span class="co"># Train outcome models (T-learner style)</span></span>
<span id="cb9-13"><a href="#cb9-13"></a>    rf_1 <span class="ot">&lt;-</span> grf<span class="sc">::</span><span class="fu">regression_forest</span>(X[train_idx <span class="sc">&amp;</span> W <span class="sc">==</span> <span class="dv">1</span>, , <span class="at">drop =</span> <span class="cn">FALSE</span>],</span>
<span id="cb9-14"><a href="#cb9-14"></a>                                    Y[train_idx <span class="sc">&amp;</span> W <span class="sc">==</span> <span class="dv">1</span>])</span>
<span id="cb9-15"><a href="#cb9-15"></a>    rf_0 <span class="ot">&lt;-</span> grf<span class="sc">::</span><span class="fu">regression_forest</span>(X[train_idx <span class="sc">&amp;</span> W <span class="sc">==</span> <span class="dv">0</span>, , <span class="at">drop =</span> <span class="cn">FALSE</span>],</span>
<span id="cb9-16"><a href="#cb9-16"></a>                                    Y[train_idx <span class="sc">&amp;</span> W <span class="sc">==</span> <span class="dv">0</span>])</span>
<span id="cb9-17"><a href="#cb9-17"></a></span>
<span id="cb9-18"><a href="#cb9-18"></a>    <span class="co"># Train propensity model</span></span>
<span id="cb9-19"><a href="#cb9-19"></a>    rf_e <span class="ot">&lt;-</span> grf<span class="sc">::</span><span class="fu">regression_forest</span>(X[train_idx, , <span class="at">drop =</span> <span class="cn">FALSE</span>],</span>
<span id="cb9-20"><a href="#cb9-20"></a>                                    W[train_idx])</span>
<span id="cb9-21"><a href="#cb9-21"></a></span>
<span id="cb9-22"><a href="#cb9-22"></a>    <span class="co"># Predict on test fold</span></span>
<span id="cb9-23"><a href="#cb9-23"></a>    mu1_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_1, X[test_idx, , <span class="at">drop =</span> <span class="cn">FALSE</span>])<span class="sc">$</span>predictions</span>
<span id="cb9-24"><a href="#cb9-24"></a>    mu0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_0, X[test_idx, , <span class="at">drop =</span> <span class="cn">FALSE</span>])<span class="sc">$</span>predictions</span>
<span id="cb9-25"><a href="#cb9-25"></a>    e_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_e, X[test_idx, , <span class="at">drop =</span> <span class="cn">FALSE</span>])<span class="sc">$</span>predictions</span>
<span id="cb9-26"><a href="#cb9-26"></a>    e_hat <span class="ot">&lt;-</span> <span class="fu">pmax</span>(<span class="fu">pmin</span>(e_hat, <span class="fl">0.99</span>), <span class="fl">0.01</span>)  <span class="co"># clip propensity</span></span>
<span id="cb9-27"><a href="#cb9-27"></a></span>
<span id="cb9-28"><a href="#cb9-28"></a>    <span class="co"># AIPW pseudo-outcome (doubly robust)</span></span>
<span id="cb9-29"><a href="#cb9-29"></a>    Y_test <span class="ot">&lt;-</span> Y[test_idx]</span>
<span id="cb9-30"><a href="#cb9-30"></a>    W_test <span class="ot">&lt;-</span> W[test_idx]</span>
<span id="cb9-31"><a href="#cb9-31"></a></span>
<span id="cb9-32"><a href="#cb9-32"></a>    psi[test_idx] <span class="ot">&lt;-</span> W_test <span class="sc">*</span> (Y_test <span class="sc">-</span> mu1_hat) <span class="sc">/</span> e_hat <span class="sc">-</span></span>
<span id="cb9-33"><a href="#cb9-33"></a>                     (<span class="dv">1</span> <span class="sc">-</span> W_test) <span class="sc">*</span> (Y_test <span class="sc">-</span> mu0_hat) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> e_hat) <span class="sc">+</span></span>
<span id="cb9-34"><a href="#cb9-34"></a>                     mu1_hat <span class="sc">-</span> mu0_hat</span>
<span id="cb9-35"><a href="#cb9-35"></a>  }</span>
<span id="cb9-36"><a href="#cb9-36"></a></span>
<span id="cb9-37"><a href="#cb9-37"></a>  <span class="co"># ATE and SE</span></span>
<span id="cb9-38"><a href="#cb9-38"></a>  tau_hat <span class="ot">&lt;-</span> <span class="fu">mean</span>(psi)</span>
<span id="cb9-39"><a href="#cb9-39"></a>  se_hat <span class="ot">&lt;-</span> <span class="fu">sd</span>(psi) <span class="sc">/</span> <span class="fu">sqrt</span>(n)</span>
<span id="cb9-40"><a href="#cb9-40"></a></span>
<span id="cb9-41"><a href="#cb9-41"></a>  <span class="fu">list</span>(</span>
<span id="cb9-42"><a href="#cb9-42"></a>    <span class="at">estimate =</span> tau_hat,</span>
<span id="cb9-43"><a href="#cb9-43"></a>    <span class="at">se =</span> se_hat,</span>
<span id="cb9-44"><a href="#cb9-44"></a>    <span class="at">ci_lower =</span> tau_hat <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> se_hat,</span>
<span id="cb9-45"><a href="#cb9-45"></a>    <span class="at">ci_upper =</span> tau_hat <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> se_hat</span>
<span id="cb9-46"><a href="#cb9-46"></a>  )</span>
<span id="cb9-47"><a href="#cb9-47"></a>}</span>
<span id="cb9-48"><a href="#cb9-48"></a></span>
<span id="cb9-49"><a href="#cb9-49"></a><span class="co"># Apply</span></span>
<span id="cb9-50"><a href="#cb9-50"></a>dml_result <span class="ot">&lt;-</span> <span class="fu">double_ml_ate</span>(Y, W, <span class="fu">as.matrix</span>(<span class="fu">cbind</span>(X1, X2)))</span>
<span id="cb9-51"><a href="#cb9-51"></a>true_ate <span class="ot">&lt;-</span> <span class="fu">mean</span>(tau_true)</span>
<span id="cb9-52"><a href="#cb9-52"></a></span>
<span id="cb9-53"><a href="#cb9-53"></a><span class="fu">cat</span>(<span class="st">"Double ML ATE:"</span>, <span class="fu">round</span>(dml_result<span class="sc">$</span>estimate, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Double ML ATE: 1.864 </code></pre>
</div>
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a><span class="fu">cat</span>(<span class="st">"SE:"</span>, <span class="fu">round</span>(dml_result<span class="sc">$</span>se, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>SE: 0.084 </code></pre>
</div>
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a><span class="fu">cat</span>(<span class="st">"True ATE:"</span>, <span class="fu">round</span>(true_ate, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>True ATE: 1.961 </code></pre>
</div>
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a><span class="fu">cat</span>(<span class="st">"95% CI: ["</span>, <span class="fu">round</span>(dml_result<span class="sc">$</span>ci_lower, <span class="dv">3</span>), <span class="st">","</span>,</span>
<span id="cb15-2"><a href="#cb15-2"></a>    <span class="fu">round</span>(dml_result<span class="sc">$</span>ci_upper, <span class="dv">3</span>), <span class="st">"]</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>95% CI: [ 1.699 , 2.029 ]</code></pre>
</div>
</div>
</section>
</section>
<section id="meta-learners" class="level1 unnumbered">
<h1 class="unnumbered">Meta-Learners</h1>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>Meta-learners are strategies for combining base ML models to estimate CATE.</p>
</section>
<section id="t-learner-two-models" class="level2">
<h2 class="anchored" data-anchor-id="t-learner-two-models">T-Learner (Two Models)</h2>
<p>Train <strong>separate</strong> models for treatment and control:</p>
<p><span class="math display">\[
\hat{\tau}(x) = \hat{\mu}_1(x) - \hat{\mu}_0(x)
\]</span></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a><span class="co"># T-Learner implementation</span></span>
<span id="cb17-2"><a href="#cb17-2"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb17-3"><a href="#cb17-3"></a></span>
<span id="cb17-4"><a href="#cb17-4"></a><span class="co"># Binary treatment simulation</span></span>
<span id="cb17-5"><a href="#cb17-5"></a>n <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb17-6"><a href="#cb17-6"></a>X_sim <span class="op">=</span> np.random.randn(n, <span class="dv">5</span>)</span>
<span id="cb17-7"><a href="#cb17-7"></a>W_sim <span class="op">=</span> np.random.binomial(<span class="dv">1</span>, <span class="fl">0.5</span>, n)</span>
<span id="cb17-8"><a href="#cb17-8"></a>tau_sim <span class="op">=</span> X_sim[:, <span class="dv">0</span>] <span class="op">+</span> <span class="fl">0.5</span> <span class="op">*</span> X_sim[:, <span class="dv">1</span>]</span>
<span id="cb17-9"><a href="#cb17-9"></a>Y_sim <span class="op">=</span> tau_sim <span class="op">*</span> W_sim <span class="op">+</span> X_sim[:, <span class="dv">0</span>] <span class="op">+</span> np.random.randn(n)</span>
<span id="cb17-10"><a href="#cb17-10"></a></span>
<span id="cb17-11"><a href="#cb17-11"></a><span class="co"># T-Learner: separate models for treatment and control</span></span>
<span id="cb17-12"><a href="#cb17-12"></a>model_0 <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb17-13"><a href="#cb17-13"></a>model_1 <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb17-14"><a href="#cb17-14"></a></span>
<span id="cb17-15"><a href="#cb17-15"></a>model_0.fit(X_sim[W_sim <span class="op">==</span> <span class="dv">0</span>], Y_sim[W_sim <span class="op">==</span> <span class="dv">0</span>])</span>
<span id="cb17-16"><a href="#cb17-16"></a>model_1.fit(X_sim[W_sim <span class="op">==</span> <span class="dv">1</span>], Y_sim[W_sim <span class="op">==</span> <span class="dv">1</span>])</span>
<span id="cb17-17"><a href="#cb17-17"></a></span>
<span id="cb17-18"><a href="#cb17-18"></a>tau_t <span class="op">=</span> model_1.predict(X_sim) <span class="op">-</span> model_0.predict(X_sim)</span>
<span id="cb17-19"><a href="#cb17-19"></a></span>
<span id="cb17-20"><a href="#cb17-20"></a><span class="bu">print</span>(<span class="ss">f"T-Learner correlation with true τ: </span><span class="sc">{</span>np<span class="sc">.</span>corrcoef(tau_sim, tau_t)[<span class="dv">0</span>,<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Pros</strong>: Simple, no propensity needed</p>
<p><strong>Cons</strong>: High variance, especially with imbalanced treatment</p>
</section>
<section id="s-learner-single-model" class="level2">
<h2 class="anchored" data-anchor-id="s-learner-single-model">S-Learner (Single Model)</h2>
<p>Single model with treatment as feature:</p>
<p><span class="math display">\[
\hat{\mu}(x, w) \rightarrow \hat{\tau}(x) = \hat{\mu}(x, 1) - \hat{\mu}(x, 0)
\]</span></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a><span class="co"># S-Learner: single model with treatment as feature</span></span>
<span id="cb18-2"><a href="#cb18-2"></a>X_aug <span class="op">=</span> np.column_stack([X_sim, W_sim])</span>
<span id="cb18-3"><a href="#cb18-3"></a>model_s <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb18-4"><a href="#cb18-4"></a>model_s.fit(X_aug, Y_sim)</span>
<span id="cb18-5"><a href="#cb18-5"></a></span>
<span id="cb18-6"><a href="#cb18-6"></a><span class="co"># Predict under treatment and control</span></span>
<span id="cb18-7"><a href="#cb18-7"></a>tau_s <span class="op">=</span> (model_s.predict(np.column_stack([X_sim, np.ones(n)])) <span class="op">-</span></span>
<span id="cb18-8"><a href="#cb18-8"></a>         model_s.predict(np.column_stack([X_sim, np.zeros(n)])))</span>
<span id="cb18-9"><a href="#cb18-9"></a></span>
<span id="cb18-10"><a href="#cb18-10"></a><span class="bu">print</span>(<span class="ss">f"S-Learner correlation with true τ: </span><span class="sc">{</span>np<span class="sc">.</span>corrcoef(tau_sim, tau_s)[<span class="dv">0</span>,<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Pros</strong>: Simple, regularization shared</p>
<p><strong>Cons</strong>: Treatment effect can be shrunk to zero</p>
</section>
<section id="x-learner-künzel-et-al.-2019" class="level2">
<h2 class="anchored" data-anchor-id="x-learner-künzel-et-al.-2019">X-Learner (Künzel et al.&nbsp;2019)</h2>
<p>Best for <strong>imbalanced treatment</strong> (few treated or few controls):</p>
<ol type="1">
<li>Fit <span class="math inline">\(\hat{\mu}_0, \hat{\mu}_1\)</span> (T-learner)</li>
<li>Impute treatment effects:
<ul>
<li>Treated: <span class="math inline">\(\tilde{D}_1 = Y_1 - \hat{\mu}_0(X_1)\)</span></li>
<li>Control: <span class="math inline">\(\tilde{D}_0 = \hat{\mu}_1(X_0) - Y_0\)</span></li>
</ul></li>
<li>Fit models: <span class="math inline">\(\hat{\tau}_0(x), \hat{\tau}_1(x)\)</span></li>
<li>Combine: <span class="math inline">\(\hat{\tau}(x) = e(x) \hat{\tau}_0(x) + (1-e(x)) \hat{\tau}_1(x)\)</span></li>
</ol>
</section>
<section id="comparison" class="level2">
<h2 class="anchored" data-anchor-id="comparison">Comparison</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 30%">
<col style="width: 36%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Learner</th>
<th>Best When</th>
<th>Weakness</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>T-Learner</strong></td>
<td>Balanced, large samples</td>
<td>High variance</td>
</tr>
<tr class="even">
<td><strong>S-Learner</strong></td>
<td>Small effects, regularization needed</td>
<td>Shrinks effects</td>
</tr>
<tr class="odd">
<td><strong>X-Learner</strong></td>
<td>Imbalanced treatment</td>
<td>Complex, needs propensity</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="group-average-treatment-effects-gates" class="level1 unnumbered">
<h1 class="unnumbered">Group Average Treatment Effects (GATES)</h1>
<section id="evaluating-heterogeneity" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-heterogeneity">Evaluating Heterogeneity</h2>
<p>GATES groups units by predicted CATE and estimates average effects within each group:</p>
<div class="cell" data-layout-align="center">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1"></a><span class="co"># GATES analysis</span></span>
<span id="cb19-2"><a href="#cb19-2"></a>tau_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(cf)<span class="sc">$</span>predictions</span>
<span id="cb19-3"><a href="#cb19-3"></a></span>
<span id="cb19-4"><a href="#cb19-4"></a><span class="co"># Create quartiles</span></span>
<span id="cb19-5"><a href="#cb19-5"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb19-6"><a href="#cb19-6"></a>  <span class="fu">mutate</span>(</span>
<span id="cb19-7"><a href="#cb19-7"></a>    <span class="at">tau_hat =</span> tau_hat,</span>
<span id="cb19-8"><a href="#cb19-8"></a>    <span class="at">quartile =</span> <span class="fu">cut</span>(tau_hat,</span>
<span id="cb19-9"><a href="#cb19-9"></a>                   <span class="at">breaks =</span> <span class="fu">quantile</span>(tau_hat, <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="dv">1</span>)),</span>
<span id="cb19-10"><a href="#cb19-10"></a>                   <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Q1 (lowest)"</span>, <span class="st">"Q2"</span>, <span class="st">"Q3"</span>, <span class="st">"Q4 (highest)"</span>),</span>
<span id="cb19-11"><a href="#cb19-11"></a>                   <span class="at">include.lowest =</span> <span class="cn">TRUE</span>)</span>
<span id="cb19-12"><a href="#cb19-12"></a>  )</span>
<span id="cb19-13"><a href="#cb19-13"></a></span>
<span id="cb19-14"><a href="#cb19-14"></a><span class="co"># Compute GATES</span></span>
<span id="cb19-15"><a href="#cb19-15"></a>gates <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb19-16"><a href="#cb19-16"></a>  <span class="fu">group_by</span>(quartile) <span class="sc">%&gt;%</span></span>
<span id="cb19-17"><a href="#cb19-17"></a>  <span class="fu">summarise</span>(</span>
<span id="cb19-18"><a href="#cb19-18"></a>    <span class="at">mean_tau_true =</span> <span class="fu">mean</span>(tau_true),</span>
<span id="cb19-19"><a href="#cb19-19"></a>    <span class="at">mean_tau_hat =</span> <span class="fu">mean</span>(tau_hat),</span>
<span id="cb19-20"><a href="#cb19-20"></a>    <span class="at">n =</span> <span class="fu">n</span>(),</span>
<span id="cb19-21"><a href="#cb19-21"></a>    <span class="at">.groups =</span> <span class="st">"drop"</span></span>
<span id="cb19-22"><a href="#cb19-22"></a>  )</span>
<span id="cb19-23"><a href="#cb19-23"></a></span>
<span id="cb19-24"><a href="#cb19-24"></a><span class="co"># Plot</span></span>
<span id="cb19-25"><a href="#cb19-25"></a><span class="fu">ggplot</span>(gates, <span class="fu">aes</span>(<span class="at">x =</span> quartile)) <span class="sc">+</span></span>
<span id="cb19-26"><a href="#cb19-26"></a>  <span class="fu">geom_bar</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean_tau_true, <span class="at">fill =</span> <span class="st">"True"</span>), <span class="at">stat =</span> <span class="st">"identity"</span>,</span>
<span id="cb19-27"><a href="#cb19-27"></a>           <span class="at">position =</span> <span class="fu">position_dodge</span>(<span class="at">width =</span> <span class="fl">0.8</span>), <span class="at">width =</span> <span class="fl">0.35</span>) <span class="sc">+</span></span>
<span id="cb19-28"><a href="#cb19-28"></a>  <span class="fu">geom_bar</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean_tau_hat, <span class="at">fill =</span> <span class="st">"Estimated"</span>), <span class="at">stat =</span> <span class="st">"identity"</span>,</span>
<span id="cb19-29"><a href="#cb19-29"></a>           <span class="at">position =</span> <span class="fu">position_dodge</span>(<span class="at">width =</span> <span class="fl">0.8</span>), <span class="at">width =</span> <span class="fl">0.35</span>) <span class="sc">+</span></span>
<span id="cb19-30"><a href="#cb19-30"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"True"</span> <span class="ot">=</span> <span class="st">"#2ecc71"</span>, <span class="st">"Estimated"</span> <span class="ot">=</span> <span class="st">"#3498db"</span>)) <span class="sc">+</span></span>
<span id="cb19-31"><a href="#cb19-31"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Group Average Treatment Effects (GATES)"</span>,</span>
<span id="cb19-32"><a href="#cb19-32"></a>       <span class="at">subtitle =</span> <span class="st">"Causal forest correctly ranks effect heterogeneity"</span>,</span>
<span id="cb19-33"><a href="#cb19-33"></a>       <span class="at">x =</span> <span class="st">"Quartile of Predicted CATE"</span>, <span class="at">y =</span> <span class="st">"Average Treatment Effect"</span>) <span class="sc">+</span></span>
<span id="cb19-34"><a href="#cb19-34"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb19-35"><a href="#cb19-35"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>, <span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13_causal_ml_files/figure-html/gates-1.png" class="img-fluid figure-img" width="960"></p>
<figcaption>GATES: Average effects by predicted CATE quartile</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="best-linear-predictor-blp" class="level2">
<h2 class="anchored" data-anchor-id="best-linear-predictor-blp">Best Linear Predictor (BLP)</h2>
<p>Which covariates <strong>explain</strong> heterogeneity?</p>
<div class="cell" data-layout-align="center">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1"></a><span class="co"># Best linear projection</span></span>
<span id="cb20-2"><a href="#cb20-2"></a>blp <span class="ot">&lt;-</span> <span class="fu">best_linear_projection</span>(cf, X)</span>
<span id="cb20-3"><a href="#cb20-3"></a><span class="fu">print</span>(blp)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Best linear projection of the conditional average treatment effect.
Confidence intervals are cluster- and heteroskedasticity-robust (HC3):

             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  1.923589   0.067767 28.3853   &lt;2e-16 ***
X1           1.522921   0.074177 20.5308   &lt;2e-16 ***
X2          -0.038501   0.071713 -0.5369   0.5915    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1"></a><span class="co"># Visualize</span></span>
<span id="cb22-2"><a href="#cb22-2"></a>blp_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb22-3"><a href="#cb22-3"></a>  <span class="at">variable =</span> <span class="fu">c</span>(<span class="st">"Intercept"</span>, <span class="st">"X1"</span>, <span class="st">"X2"</span>),</span>
<span id="cb22-4"><a href="#cb22-4"></a>  <span class="at">estimate =</span> blp[, <span class="dv">1</span>],</span>
<span id="cb22-5"><a href="#cb22-5"></a>  <span class="at">se =</span> blp[, <span class="dv">2</span>]</span>
<span id="cb22-6"><a href="#cb22-6"></a>)</span>
<span id="cb22-7"><a href="#cb22-7"></a></span>
<span id="cb22-8"><a href="#cb22-8"></a><span class="fu">ggplot</span>(blp_df, <span class="fu">aes</span>(<span class="at">x =</span> variable, <span class="at">y =</span> estimate)) <span class="sc">+</span></span>
<span id="cb22-9"><a href="#cb22-9"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>, <span class="at">color =</span> <span class="st">"#3498db"</span>) <span class="sc">+</span></span>
<span id="cb22-10"><a href="#cb22-10"></a>  <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> estimate <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> se, <span class="at">ymax =</span> estimate <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> se),</span>
<span id="cb22-11"><a href="#cb22-11"></a>                <span class="at">width =</span> <span class="fl">0.2</span>, <span class="at">color =</span> <span class="st">"#3498db"</span>) <span class="sc">+</span></span>
<span id="cb22-12"><a href="#cb22-12"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb22-13"><a href="#cb22-13"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Best Linear Predictor of CATE"</span>,</span>
<span id="cb22-14"><a href="#cb22-14"></a>       <span class="at">subtitle =</span> <span class="st">"X₁ significantly predicts heterogeneity (coefficient ≈ 1.5)"</span>,</span>
<span id="cb22-15"><a href="#cb22-15"></a>       <span class="at">x =</span> <span class="cn">NULL</span>, <span class="at">y =</span> <span class="st">"Coefficient"</span>) <span class="sc">+</span></span>
<span id="cb22-16"><a href="#cb22-16"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="13_causal_ml_files/figure-html/blp-1.png" class="img-fluid figure-img" width="960"></p>
<figcaption>Best linear predictor identifies X₁ as heterogeneity driver</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="econml-microsofts-causal-ml-toolkit" class="level1 unnumbered">
<h1 class="unnumbered">EconML: Microsoft’s Causal ML Toolkit</h1>
<section id="overview-1" class="level2">
<h2 class="anchored" data-anchor-id="overview-1">Overview</h2>
<p>EconML provides a <strong>unified API</strong> for heterogeneous treatment effect estimation in Python.</p>
</section>
<section id="key-estimators" class="level2">
<h2 class="anchored" data-anchor-id="key-estimators">Key Estimators</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Estimator</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>LinearDML</code></td>
<td>DML with linear final stage</td>
</tr>
<tr class="even">
<td><code>CausalForestDML</code></td>
<td>Causal forest with DML</td>
</tr>
<tr class="odd">
<td><code>ForestDRLearner</code></td>
<td>Doubly robust forest</td>
</tr>
<tr class="even">
<td><code>OrthoIV</code></td>
<td>Orthogonal IV learner</td>
</tr>
<tr class="odd">
<td><code>DynamicDML</code></td>
<td>Panel data</td>
</tr>
</tbody>
</table>
</section>
<section id="python-implementation" class="level2">
<h2 class="anchored" data-anchor-id="python-implementation">Python Implementation</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a><span class="co"># EconML example</span></span>
<span id="cb23-2"><a href="#cb23-2"></a><span class="im">from</span> econml.dml <span class="im">import</span> LinearDML, CausalForestDML</span>
<span id="cb23-3"><a href="#cb23-3"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor, RandomForestClassifier</span>
<span id="cb23-4"><a href="#cb23-4"></a></span>
<span id="cb23-5"><a href="#cb23-5"></a><span class="co"># Setup</span></span>
<span id="cb23-6"><a href="#cb23-6"></a>X_hetero <span class="op">=</span> X_sim[:, :<span class="dv">3</span>]  <span class="co"># features for heterogeneity</span></span>
<span id="cb23-7"><a href="#cb23-7"></a>W_confound <span class="op">=</span> X_sim[:, <span class="dv">3</span>:]  <span class="co"># confounders</span></span>
<span id="cb23-8"><a href="#cb23-8"></a></span>
<span id="cb23-9"><a href="#cb23-9"></a><span class="co"># LinearDML</span></span>
<span id="cb23-10"><a href="#cb23-10"></a>est_linear <span class="op">=</span> LinearDML(</span>
<span id="cb23-11"><a href="#cb23-11"></a>    model_y<span class="op">=</span>RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>),</span>
<span id="cb23-12"><a href="#cb23-12"></a>    model_t<span class="op">=</span>RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>),</span>
<span id="cb23-13"><a href="#cb23-13"></a>    cv<span class="op">=</span><span class="dv">5</span></span>
<span id="cb23-14"><a href="#cb23-14"></a>)</span>
<span id="cb23-15"><a href="#cb23-15"></a>est_linear.fit(Y_sim, W_sim, X<span class="op">=</span>X_hetero, W<span class="op">=</span>W_confound)</span>
<span id="cb23-16"><a href="#cb23-16"></a></span>
<span id="cb23-17"><a href="#cb23-17"></a><span class="co"># Effects</span></span>
<span id="cb23-18"><a href="#cb23-18"></a>tau_linear <span class="op">=</span> est_linear.effect(X_hetero)</span>
<span id="cb23-19"><a href="#cb23-19"></a></span>
<span id="cb23-20"><a href="#cb23-20"></a><span class="co"># Inference</span></span>
<span id="cb23-21"><a href="#cb23-21"></a>tau_lower, tau_upper <span class="op">=</span> est_linear.effect_interval(X_hetero, alpha<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb23-22"><a href="#cb23-22"></a></span>
<span id="cb23-23"><a href="#cb23-23"></a><span class="co"># Summary</span></span>
<span id="cb23-24"><a href="#cb23-24"></a><span class="bu">print</span>(est_linear.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="unified-api-pattern" class="level2">
<h2 class="anchored" data-anchor-id="unified-api-pattern">Unified API Pattern</h2>
<p>All EconML estimators follow:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a>est.fit(Y, T, X<span class="op">=</span>X, W<span class="op">=</span>W)           <span class="co"># fit (Y=outcome, T=treatment, X=hetero, W=confound)</span></span>
<span id="cb24-2"><a href="#cb24-2"></a>est.effect(X_test)                 <span class="co"># point estimates</span></span>
<span id="cb24-3"><a href="#cb24-3"></a>est.effect_interval(X_test)        <span class="co"># confidence intervals</span></span>
<span id="cb24-4"><a href="#cb24-4"></a>est.summary()                      <span class="co"># inference summary</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
</section>
<section id="applications-in-macroeconomics" class="level1 unnumbered">
<h1 class="unnumbered">Applications in Macroeconomics</h1>
<section id="heterogeneous-policy-effects" class="level2">
<h2 class="anchored" data-anchor-id="heterogeneous-policy-effects">Heterogeneous Policy Effects</h2>
<p><strong>Question</strong>: How do monetary policy effects vary across firms/regions/time?</p>
<p><strong>Approach</strong>:</p>
<ol type="1">
<li>Identify policy shocks (high-frequency, narrative)</li>
<li>Estimate heterogeneous effects using causal forests</li>
<li>Characterize which observables predict sensitivity</li>
</ol>
</section>
<section id="example-cross-country-monetary-transmission" class="level2">
<h2 class="anchored" data-anchor-id="example-cross-country-monetary-transmission">Example: Cross-Country Monetary Transmission</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb25"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1"></a><span class="co"># Do bank holdings predict constrained monetary response?</span></span>
<span id="cb25-2"><a href="#cb25-2"></a>cf_policy <span class="ot">&lt;-</span> <span class="fu">causal_forest</span>(</span>
<span id="cb25-3"><a href="#cb25-3"></a>  <span class="at">X =</span> <span class="fu">cbind</span>(bank_holdings, cbi_index, debt_gdp, trade_openness),</span>
<span id="cb25-4"><a href="#cb25-4"></a>  <span class="at">Y =</span> delta_inflation,</span>
<span id="cb25-5"><a href="#cb25-5"></a>  <span class="at">W =</span> tightening_dummy</span>
<span id="cb25-6"><a href="#cb25-6"></a>)</span>
<span id="cb25-7"><a href="#cb25-7"></a></span>
<span id="cb25-8"><a href="#cb25-8"></a><span class="co"># Which characteristics drive heterogeneity?</span></span>
<span id="cb25-9"><a href="#cb25-9"></a><span class="fu">variable_importance</span>(cf_policy)</span>
<span id="cb25-10"><a href="#cb25-10"></a></span>
<span id="cb25-11"><a href="#cb25-11"></a><span class="co"># Linear approximation</span></span>
<span id="cb25-12"><a href="#cb25-12"></a><span class="fu">best_linear_projection</span>(cf_policy,</span>
<span id="cb25-13"><a href="#cb25-13"></a>                       <span class="fu">cbind</span>(bank_holdings, cbi_index, debt_gdp))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="fiscal-multiplier-heterogeneity" class="level2">
<h2 class="anchored" data-anchor-id="fiscal-multiplier-heterogeneity">Fiscal Multiplier Heterogeneity</h2>
<p>Do fiscal multipliers vary by:</p>
<ul>
<li>Slack (output gap)?</li>
<li>Monetary policy stance (ZLB)?</li>
<li>Debt levels?</li>
</ul>
<p>Causal forests can flexibly estimate: <span class="math display">\[
\text{Multiplier}(x) = \mathbb{E}[\Delta Y \mid \text{Fiscal shock}, X = x]
\]</span></p>
</section>
</section>
<section id="practical-considerations" class="level1 unnumbered">
<h1 class="unnumbered">Practical Considerations</h1>
<section id="sample-size-requirements" class="level2">
<h2 class="anchored" data-anchor-id="sample-size-requirements">Sample Size Requirements</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Method</th>
<th>Minimum N</th>
<th>Recommended N</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ATE (Double ML)</td>
<td>200</td>
<td>500+</td>
</tr>
<tr class="even">
<td>CATE (Causal Forest)</td>
<td>500</td>
<td>2000+</td>
</tr>
<tr class="odd">
<td>GATES</td>
<td>1000</td>
<td>3000+</td>
</tr>
<tr class="even">
<td>Variable Importance</td>
<td>2000</td>
<td>5000+</td>
</tr>
</tbody>
</table>
</section>
<section id="diagnostics" class="level2">
<h2 class="anchored" data-anchor-id="diagnostics">Diagnostics</h2>
<section id="overlap-check" class="level3">
<h3 class="anchored" data-anchor-id="overlap-check">Overlap Check</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb26"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1"></a><span class="co"># Propensity score distribution</span></span>
<span id="cb26-2"><a href="#cb26-2"></a>e_hat <span class="ot">&lt;-</span> cf<span class="sc">$</span>W.hat</span>
<span id="cb26-3"><a href="#cb26-3"></a><span class="fu">hist</span>(e_hat, <span class="at">breaks =</span> <span class="dv">50</span>, <span class="at">main =</span> <span class="st">"Propensity Scores"</span>)</span>
<span id="cb26-4"><a href="#cb26-4"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.9</span>), <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb26-5"><a href="#cb26-5"></a></span>
<span id="cb26-6"><a href="#cb26-6"></a><span class="co"># Extreme values</span></span>
<span id="cb26-7"><a href="#cb26-7"></a><span class="fu">cat</span>(<span class="st">"Extreme propensity:"</span>, <span class="fu">mean</span>(e_hat <span class="sc">&lt;</span> <span class="fl">0.1</span> <span class="sc">|</span> e_hat <span class="sc">&gt;</span> <span class="fl">0.9</span>) <span class="sc">*</span> <span class="dv">100</span>, <span class="st">"%</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="calibration-test" class="level3">
<h3 class="anchored" data-anchor-id="calibration-test">Calibration Test</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb27"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1"></a><span class="co"># Is there actually heterogeneity?</span></span>
<span id="cb27-2"><a href="#cb27-2"></a><span class="fu">test_calibration</span>(cf)</span>
<span id="cb27-3"><a href="#cb27-3"></a><span class="co"># Look for significant "differential.forest.prediction"</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="autoc-targeting-quality" class="level3">
<h3 class="anchored" data-anchor-id="autoc-targeting-quality">AUTOC (Targeting Quality)</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb28"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1"></a><span class="co"># Area Under the TOC Curve</span></span>
<span id="cb28-2"><a href="#cb28-2"></a>rate <span class="ot">&lt;-</span> <span class="fu">rank_average_treatment_effect</span>(cf, X[, <span class="dv">1</span>])</span>
<span id="cb28-3"><a href="#cb28-3"></a><span class="fu">print</span>(rate)  <span class="co"># CI should exclude 0</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
</section>
<section id="common-pitfalls" class="level2">
<h2 class="anchored" data-anchor-id="common-pitfalls">Common Pitfalls</h2>
<ol type="1">
<li><strong>Causal ML doesn’t solve identification</strong>: Still need unconfoundedness</li>
<li><strong>Overfitting CATE</strong>: Use honest forests, cross-validation</li>
<li><strong>Noise as heterogeneity</strong>: Run calibration tests</li>
<li><strong>Overlap violations</strong>: Check propensity scores, trim extremes</li>
<li><strong>Small samples</strong>: CATE unreliable with N &lt; 500</li>
</ol>
</section>
</section>
<section id="summary" class="level1 unnumbered">
<h1 class="unnumbered">Summary</h1>
<table class="caption-top table">
<colgroup>
<col style="width: 30%">
<col style="width: 34%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Purpose</th>
<th>Package</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Causal Forest</strong></td>
<td>Heterogeneous treatment effects</td>
<td><code>grf</code> (R)</td>
</tr>
<tr class="even">
<td><strong>Double ML</strong></td>
<td>ATE with high-dimensional controls</td>
<td><code>DoubleML</code> (Python/R)</td>
</tr>
<tr class="odd">
<td><strong>EconML</strong></td>
<td>Unified CATE estimation</td>
<td><code>econml</code> (Python)</td>
</tr>
<tr class="even">
<td><strong>Meta-Learners</strong></td>
<td>T/S/X strategies for CATE</td>
<td>Various</td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>For Macro Applications
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><strong>Sample sizes matter</strong>: Cross-country panels may be too small for CATE</li>
<li><strong>Identification first</strong>: Causal ML requires the same assumptions as traditional methods</li>
<li><strong>Focus on BLP and GATES</strong>: Which characteristics predict heterogeneity?</li>
<li><strong>Aggregation concerns</strong>: Individual effects may aggregate differently at macro level</li>
</ol>
</div>
</div>
</section>
<section id="key-references" class="level1 unnumbered">
<h1 class="unnumbered">Key References</h1>
<section id="foundational" class="level2">
<h2 class="anchored" data-anchor-id="foundational">Foundational</h2>
<ul>
<li><strong>Athey &amp; Imbens (2016)</strong> “Recursive Partitioning for Heterogeneous Causal Effects” PNAS</li>
<li><strong>Wager &amp; Athey (2018)</strong> “Estimation and Inference of Heterogeneous Treatment Effects using Random Forests” JASA</li>
<li><strong>Chernozhukov et al.&nbsp;(2018)</strong> “Double/Debiased Machine Learning” Econometrics Journal</li>
</ul>
</section>
<section id="extensions" class="level2">
<h2 class="anchored" data-anchor-id="extensions">Extensions</h2>
<ul>
<li><strong>Künzel et al.&nbsp;(2019)</strong> “Metalearners for Heterogeneous Treatment Effects” PNAS</li>
<li><strong>Athey &amp; Wager (2021)</strong> “Policy Learning with Observational Data” Econometrica</li>
<li><strong>Kennedy (2022)</strong> “Optimal Doubly Robust Estimation of Heterogeneous Causal Effects”</li>
</ul>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">Resources</h2>
<ul>
<li><strong>Causal ML Book</strong>: https://causalml-book.org/</li>
<li><strong>ML for Economists</strong>: https://github.com/ml4econ/lecture-notes-2025</li>
<li><strong>grf Documentation</strong>: https://grf-labs.github.io/grf/</li>
<li><strong>EconML</strong>: https://github.com/py-why/EconML</li>
<li><strong>DoubleML</strong>: https://github.com/DoubleML/doubleml-for-py</li>
</ul>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-athey2019" class="csl-entry" role="listitem">
Athey, Susan, and Guido W Imbens. 2019. <span>“Machine Learning Methods That Economists Should Know About.”</span> <em>Annual Review of Economics</em> 11: 685–725.
</div>
<div id="ref-chernozhukov2018" class="csl-entry" role="listitem">
Chernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. 2018. <span>“Double/Debiased Machine Learning for Treatment and Structural Parameters.”</span> <em>The Econometrics Journal</em> 21 (1): C1–68.
</div>
<div id="ref-wager2018" class="csl-entry" role="listitem">
Wager, Stefan, and Susan Athey. 2018. <span>“Estimation and Inference of Heterogeneous Treatment Effects Using Random Forests.”</span> <em>Journal of the American Statistical Association</em> 113 (523): 1228–42.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/12_regularization.html" class="pagination-link" aria-label="Regularization for Macro">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Regularization for Macro</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../references.html" class="pagination-link" aria-label="References">
        <span class="nav-page-text"><span class="chapter-title">References</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb29" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb29-1"><a href="#cb29-1"></a><span class="co">---</span></span>
<span id="cb29-2"><a href="#cb29-2"></a><span class="an">title:</span><span class="co"> "Causal Machine Learning"</span></span>
<span id="cb29-3"><a href="#cb29-3"></a><span class="an">subtitle:</span><span class="co"> "Heterogeneous Treatment Effects, Causal Forests, and Double ML"</span></span>
<span id="cb29-4"><a href="#cb29-4"></a><span class="co">---</span></span>
<span id="cb29-5"><a href="#cb29-5"></a></span>
<span id="cb29-8"><a href="#cb29-8"></a><span class="in">```{r}</span></span>
<span id="cb29-9"><a href="#cb29-9"></a><span class="co">#| label: setup</span></span>
<span id="cb29-10"><a href="#cb29-10"></a><span class="co">#| include: false</span></span>
<span id="cb29-11"><a href="#cb29-11"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb29-12"><a href="#cb29-12"></a><span class="co"># Note: grf package required for causal forests</span></span>
<span id="cb29-13"><a href="#cb29-13"></a><span class="co"># install.packages("grf")</span></span>
<span id="cb29-14"><a href="#cb29-14"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb29-15"><a href="#cb29-15"></a><span class="in">```</span></span>
<span id="cb29-16"><a href="#cb29-16"></a></span>
<span id="cb29-17"><a href="#cb29-17"></a><span class="in">```python</span></span>
<span id="cb29-18"><a href="#cb29-18"></a><span class="co"># Python setup (run in your Python environment)</span></span>
<span id="cb29-19"><a href="#cb29-19"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb29-20"><a href="#cb29-20"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb29-21"><a href="#cb29-21"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb29-22"><a href="#cb29-22"></a><span class="in">```</span></span>
<span id="cb29-23"><a href="#cb29-23"></a></span>
<span id="cb29-24"><a href="#cb29-24"></a><span class="fu"># From Prediction to Causation {.unnumbered}</span></span>
<span id="cb29-25"><a href="#cb29-25"></a></span>
<span id="cb29-26"><a href="#cb29-26"></a>Machine learning excels at **prediction**: minimizing $\mathbb{E}[(Y - \hat{f}(X))^2]$. But economists care about **causation**: what happens to $Y$ if we *intervene* on $X$?</span>
<span id="cb29-27"><a href="#cb29-27"></a></span>
<span id="cb29-28"><a href="#cb29-28"></a><span class="pp">|</span> Goal <span class="pp">|</span> Question <span class="pp">|</span> Method <span class="pp">|</span></span>
<span id="cb29-29"><a href="#cb29-29"></a><span class="pp">|------|----------|--------|</span></span>
<span id="cb29-30"><a href="#cb29-30"></a><span class="pp">|</span> **Prediction** <span class="pp">|</span> What is $\hat{y}$ given $x$? <span class="pp">|</span> Random forest, neural net, boosting <span class="pp">|</span></span>
<span id="cb29-31"><a href="#cb29-31"></a><span class="pp">|</span> **Causation** <span class="pp">|</span> What happens to $y$ if we change $x$? <span class="pp">|</span> Experiments, IV, DiD, RDD <span class="pp">|</span></span>
<span id="cb29-32"><a href="#cb29-32"></a></span>
<span id="cb29-33"><a href="#cb29-33"></a>::: {.callout-note}</span>
<span id="cb29-34"><a href="#cb29-34"></a><span class="fu">## The Causal ML Revolution</span></span>
<span id="cb29-35"><a href="#cb29-35"></a>Recent methods—causal forests, double ML, meta-learners—combine ML's flexibility for high-dimensional data with causal inference's focus on identification <span class="co">[</span><span class="ot">@athey2019</span><span class="co">]</span>. The key insight: use ML for **nuisance parameters** (propensity scores, outcome models) while preserving valid **causal inference**. Key methodological foundations include causal forests <span class="co">[</span><span class="ot">@wager2018</span><span class="co">]</span> and double/debiased ML <span class="co">[</span><span class="ot">@chernozhukov2018</span><span class="co">]</span>.</span>
<span id="cb29-36"><a href="#cb29-36"></a>:::</span>
<span id="cb29-37"><a href="#cb29-37"></a></span>
<span id="cb29-38"><a href="#cb29-38"></a><span class="fu">## Key Papers</span></span>
<span id="cb29-39"><a href="#cb29-39"></a></span>
<span id="cb29-40"><a href="#cb29-40"></a><span class="pp">|</span> Paper <span class="pp">|</span> Contribution <span class="pp">|</span></span>
<span id="cb29-41"><a href="#cb29-41"></a><span class="pp">|-------|--------------|</span></span>
<span id="cb29-42"><a href="#cb29-42"></a><span class="pp">|</span> **Athey &amp; Imbens (2016)** <span class="pp">|</span> Recursive partitioning for heterogeneous causal effects <span class="pp">|</span></span>
<span id="cb29-43"><a href="#cb29-43"></a><span class="pp">|</span> **Wager &amp; Athey (2018)** <span class="pp">|</span> Causal forests with valid asymptotic inference <span class="pp">|</span></span>
<span id="cb29-44"><a href="#cb29-44"></a><span class="pp">|</span> **Chernozhukov et al. (2018)** <span class="pp">|</span> Double/Debiased ML for high-dimensional controls <span class="pp">|</span></span>
<span id="cb29-45"><a href="#cb29-45"></a><span class="pp">|</span> **Künzel et al. (2019)** <span class="pp">|</span> Meta-learners (X-learner) for CATE <span class="pp">|</span></span>
<span id="cb29-46"><a href="#cb29-46"></a><span class="pp">|</span> **Athey &amp; Wager (2021)** <span class="pp">|</span> Policy learning with observational data <span class="pp">|</span></span>
<span id="cb29-47"><a href="#cb29-47"></a></span>
<span id="cb29-48"><a href="#cb29-48"></a><span class="fu"># The Potential Outcomes Framework {.unnumbered}</span></span>
<span id="cb29-49"><a href="#cb29-49"></a></span>
<span id="cb29-50"><a href="#cb29-50"></a><span class="fu">## Setup</span></span>
<span id="cb29-51"><a href="#cb29-51"></a></span>
<span id="cb29-52"><a href="#cb29-52"></a>For each unit $i$:</span>
<span id="cb29-53"><a href="#cb29-53"></a></span>
<span id="cb29-54"><a href="#cb29-54"></a><span class="ss">- </span>**Treatment**: $W_i \in <span class="sc">\{</span>0, 1<span class="sc">\}</span>$</span>
<span id="cb29-55"><a href="#cb29-55"></a><span class="ss">- </span>**Potential outcomes**: $Y_i(0), Y_i(1)$ — what would happen under control/treatment</span>
<span id="cb29-56"><a href="#cb29-56"></a><span class="ss">- </span>**Observed outcome**: $Y_i = W_i \cdot Y_i(1) + (1 - W_i) \cdot Y_i(0)$</span>
<span id="cb29-57"><a href="#cb29-57"></a><span class="ss">- </span>**Covariates**: $X_i$ (pre-treatment characteristics)</span>
<span id="cb29-58"><a href="#cb29-58"></a></span>
<span id="cb29-59"><a href="#cb29-59"></a><span class="fu">## Treatment Effects Taxonomy</span></span>
<span id="cb29-60"><a href="#cb29-60"></a></span>
<span id="cb29-61"><a href="#cb29-61"></a><span class="pp">|</span> Estimand <span class="pp">|</span> Definition <span class="pp">|</span> Interpretation <span class="pp">|</span></span>
<span id="cb29-62"><a href="#cb29-62"></a><span class="pp">|----------|------------|----------------|</span></span>
<span id="cb29-63"><a href="#cb29-63"></a><span class="pp">|</span> **ITE** <span class="pp">|</span> $\tau_i = Y_i(1) - Y_i(0)$ <span class="pp">|</span> Individual effect (unobservable) <span class="pp">|</span></span>
<span id="cb29-64"><a href="#cb29-64"></a><span class="pp">|</span> **CATE** <span class="pp">|</span> $\tau(x) = \mathbb{E}<span class="co">[</span><span class="ot">Y(1) - Y(0) \mid X = x</span><span class="co">]</span>$ <span class="pp">|</span> Conditional average effect <span class="pp">|</span></span>
<span id="cb29-65"><a href="#cb29-65"></a><span class="pp">|</span> **ATE** <span class="pp">|</span> $\mathbb{E}<span class="co">[</span><span class="ot">\tau_i</span><span class="co">]</span>$ <span class="pp">|</span> Average treatment effect <span class="pp">|</span></span>
<span id="cb29-66"><a href="#cb29-66"></a><span class="pp">|</span> **ATT** <span class="pp">|</span> $\mathbb{E}<span class="co">[</span><span class="ot">\tau_i \mid W_i = 1</span><span class="co">]</span>$ <span class="pp">|</span> Effect on the treated <span class="pp">|</span></span>
<span id="cb29-67"><a href="#cb29-67"></a></span>
<span id="cb29-68"><a href="#cb29-68"></a><span class="fu">## The Fundamental Problem of Causal Inference</span></span>
<span id="cb29-69"><a href="#cb29-69"></a></span>
<span id="cb29-70"><a href="#cb29-70"></a>We observe either $Y_i(1)$ OR $Y_i(0)$, never both. The individual treatment effect $\tau_i$ is **fundamentally unidentifiable**.</span>
<span id="cb29-71"><a href="#cb29-71"></a></span>
<span id="cb29-72"><a href="#cb29-72"></a>**Solution**: Under **unconfoundedness** (selection on observables):</span>
<span id="cb29-73"><a href="#cb29-73"></a>$$</span>
<span id="cb29-74"><a href="#cb29-74"></a>(Y_i(0), Y_i(1)) \perp<span class="sc">\!\!\!</span>\perp W_i \mid X_i</span>
<span id="cb29-75"><a href="#cb29-75"></a>$$</span>
<span id="cb29-76"><a href="#cb29-76"></a></span>
<span id="cb29-77"><a href="#cb29-77"></a>Plus **overlap** (positivity): $0 &lt; P(W_i = 1 \mid X_i = x) &lt; 1$ for all $x$.</span>
<span id="cb29-78"><a href="#cb29-78"></a></span>
<span id="cb29-79"><a href="#cb29-79"></a><span class="fu"># Heterogeneous Treatment Effects {.unnumbered}</span></span>
<span id="cb29-80"><a href="#cb29-80"></a></span>
<span id="cb29-81"><a href="#cb29-81"></a><span class="fu">## Why Heterogeneity Matters</span></span>
<span id="cb29-82"><a href="#cb29-82"></a></span>
<span id="cb29-83"><a href="#cb29-83"></a>The ATE $= 2$ could mask:</span>
<span id="cb29-84"><a href="#cb29-84"></a></span>
<span id="cb29-85"><a href="#cb29-85"></a><span class="ss">- </span>Subgroup A: $\tau = 5$ (strong benefit)</span>
<span id="cb29-86"><a href="#cb29-86"></a><span class="ss">- </span>Subgroup B: $\tau = -1$ (harm)</span>
<span id="cb29-87"><a href="#cb29-87"></a></span>
<span id="cb29-88"><a href="#cb29-88"></a>Understanding heterogeneity enables:</span>
<span id="cb29-89"><a href="#cb29-89"></a></span>
<span id="cb29-90"><a href="#cb29-90"></a><span class="ss">1. </span>**Targeting**: Treat those who benefit most</span>
<span id="cb29-91"><a href="#cb29-91"></a><span class="ss">2. </span>**Mechanism identification**: What drives variation?</span>
<span id="cb29-92"><a href="#cb29-92"></a><span class="ss">3. </span>**Policy optimization**: Maximize welfare under constraints</span>
<span id="cb29-93"><a href="#cb29-93"></a></span>
<span id="cb29-96"><a href="#cb29-96"></a><span class="in">```{r}</span></span>
<span id="cb29-97"><a href="#cb29-97"></a><span class="co">#| label: heterogeneity-demo</span></span>
<span id="cb29-98"><a href="#cb29-98"></a><span class="co">#| fig-cap: "Treatment effect heterogeneity: τ(x) = 2 + 1.5X₁"</span></span>
<span id="cb29-99"><a href="#cb29-99"></a></span>
<span id="cb29-100"><a href="#cb29-100"></a><span class="co"># Simulate heterogeneous effects</span></span>
<span id="cb29-101"><a href="#cb29-101"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb29-102"><a href="#cb29-102"></a>X1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb29-103"><a href="#cb29-103"></a>X2 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb29-104"><a href="#cb29-104"></a></span>
<span id="cb29-105"><a href="#cb29-105"></a><span class="co"># Treatment effect depends on X1</span></span>
<span id="cb29-106"><a href="#cb29-106"></a>tau_true <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">+</span> <span class="fl">1.5</span> <span class="sc">*</span> X1</span>
<span id="cb29-107"><a href="#cb29-107"></a></span>
<span id="cb29-108"><a href="#cb29-108"></a><span class="co"># Treatment assignment (randomized)</span></span>
<span id="cb29-109"><a href="#cb29-109"></a>W <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fl">0.5</span>)</span>
<span id="cb29-110"><a href="#cb29-110"></a></span>
<span id="cb29-111"><a href="#cb29-111"></a><span class="co"># Potential outcomes</span></span>
<span id="cb29-112"><a href="#cb29-112"></a>Y0 <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fl">0.5</span> <span class="sc">*</span> X1 <span class="sc">+</span> <span class="fl">0.3</span> <span class="sc">*</span> X2 <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb29-113"><a href="#cb29-113"></a>Y1 <span class="ot">&lt;-</span> Y0 <span class="sc">+</span> tau_true</span>
<span id="cb29-114"><a href="#cb29-114"></a>Y <span class="ot">&lt;-</span> W <span class="sc">*</span> Y1 <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> W) <span class="sc">*</span> Y0</span>
<span id="cb29-115"><a href="#cb29-115"></a></span>
<span id="cb29-116"><a href="#cb29-116"></a><span class="co"># Create data frame</span></span>
<span id="cb29-117"><a href="#cb29-117"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">Y =</span> Y, <span class="at">W =</span> W, <span class="at">X1 =</span> X1, <span class="at">X2 =</span> X2, <span class="at">tau_true =</span> tau_true)</span>
<span id="cb29-118"><a href="#cb29-118"></a></span>
<span id="cb29-119"><a href="#cb29-119"></a><span class="co"># Show heterogeneity</span></span>
<span id="cb29-120"><a href="#cb29-120"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> X1, <span class="at">y =</span> tau_true)) <span class="sc">+</span></span>
<span id="cb29-121"><a href="#cb29-121"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">color =</span> <span class="st">"#3498db"</span>) <span class="sc">+</span></span>
<span id="cb29-122"><a href="#cb29-122"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">color =</span> <span class="st">"#e74c3c"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb29-123"><a href="#cb29-123"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">mean</span>(tau_true), <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"#2ecc71"</span>) <span class="sc">+</span></span>
<span id="cb29-124"><a href="#cb29-124"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">2</span>, <span class="at">y =</span> <span class="fu">mean</span>(tau_true) <span class="sc">+</span> <span class="fl">0.3</span>, <span class="at">label =</span> <span class="st">"ATE"</span>, <span class="at">color =</span> <span class="st">"#2ecc71"</span>) <span class="sc">+</span></span>
<span id="cb29-125"><a href="#cb29-125"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"True Treatment Effect Varies with X₁"</span>,</span>
<span id="cb29-126"><a href="#cb29-126"></a>       <span class="at">subtitle =</span> <span class="st">"ATE masks substantial heterogeneity"</span>,</span>
<span id="cb29-127"><a href="#cb29-127"></a>       <span class="at">x =</span> <span class="fu">expression</span>(X[<span class="dv">1</span>]), <span class="at">y =</span> <span class="st">"True Treatment Effect τ(x)"</span>) <span class="sc">+</span></span>
<span id="cb29-128"><a href="#cb29-128"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb29-129"><a href="#cb29-129"></a><span class="in">```</span></span>
<span id="cb29-130"><a href="#cb29-130"></a></span>
<span id="cb29-131"><a href="#cb29-131"></a><span class="fu">## Traditional Approaches and Their Limitations</span></span>
<span id="cb29-132"><a href="#cb29-132"></a></span>
<span id="cb29-133"><a href="#cb29-133"></a>**Subgroup analysis**: Pre-specify groups, estimate effects within each.</span>
<span id="cb29-134"><a href="#cb29-134"></a></span>
<span id="cb29-135"><a href="#cb29-135"></a><span class="ss">- </span>Problem: Many possible subgroups → multiple testing</span>
<span id="cb29-136"><a href="#cb29-136"></a><span class="ss">- </span>Problem: Boundaries are arbitrary</span>
<span id="cb29-137"><a href="#cb29-137"></a></span>
<span id="cb29-138"><a href="#cb29-138"></a>**Interaction terms**: $Y = \alpha + \tau W + \gamma W \cdot X + \beta X + \varepsilon$</span>
<span id="cb29-139"><a href="#cb29-139"></a></span>
<span id="cb29-140"><a href="#cb29-140"></a><span class="ss">- </span>Problem: Must specify functional form</span>
<span id="cb29-141"><a href="#cb29-141"></a><span class="ss">- </span>Problem: Doesn't scale to many $X$</span>
<span id="cb29-142"><a href="#cb29-142"></a></span>
<span id="cb29-143"><a href="#cb29-143"></a>**Causal ML**: Learn $\tau(x)$ flexibly from data with valid inference.</span>
<span id="cb29-144"><a href="#cb29-144"></a></span>
<span id="cb29-145"><a href="#cb29-145"></a><span class="fu"># Causal Forests {.unnumbered}</span></span>
<span id="cb29-146"><a href="#cb29-146"></a></span>
<span id="cb29-147"><a href="#cb29-147"></a><span class="fu">## The Key Idea (Wager &amp; Athey 2018)</span></span>
<span id="cb29-148"><a href="#cb29-148"></a></span>
<span id="cb29-149"><a href="#cb29-149"></a>Adapt random forests from predicting $\mathbb{E}<span class="co">[</span><span class="ot">Y|X</span><span class="co">]</span>$ to predicting $\tau(x) = \mathbb{E}<span class="co">[</span><span class="ot">Y(1) - Y(0)|X=x</span><span class="co">]</span>$.</span>
<span id="cb29-150"><a href="#cb29-150"></a></span>
<span id="cb29-151"><a href="#cb29-151"></a>**Key innovations**:</span>
<span id="cb29-152"><a href="#cb29-152"></a></span>
<span id="cb29-153"><a href="#cb29-153"></a><span class="ss">1. </span>**Honest splitting**: Separate samples for tree structure vs. leaf estimation</span>
<span id="cb29-154"><a href="#cb29-154"></a><span class="ss">2. </span>**Heterogeneity-maximizing splits**: Split to maximize treatment effect variation</span>
<span id="cb29-155"><a href="#cb29-155"></a><span class="ss">3. </span>**Valid inference**: Asymptotic normality of estimates</span>
<span id="cb29-156"><a href="#cb29-156"></a></span>
<span id="cb29-157"><a href="#cb29-157"></a><span class="fu">## Algorithm</span></span>
<span id="cb29-158"><a href="#cb29-158"></a></span>
<span id="cb29-159"><a href="#cb29-159"></a>For each tree $b = 1, \ldots, B$:</span>
<span id="cb29-160"><a href="#cb29-160"></a></span>
<span id="cb29-161"><a href="#cb29-161"></a><span class="ss">1. </span>**Subsample** data into tree-building ($\mathcal{I}_1$) and estimation ($\mathcal{I}_2$) sets</span>
<span id="cb29-162"><a href="#cb29-162"></a><span class="ss">2. </span>**Build tree** on $\mathcal{I}_1$: at each node, find split maximizing heterogeneity</span>
<span id="cb29-163"><a href="#cb29-163"></a><span class="ss">3. </span>**Estimate leaf effects** using $\mathcal{I}_2$ only (honesty)</span>
<span id="cb29-164"><a href="#cb29-164"></a><span class="ss">4. </span>**Aggregate**: $\hat{\tau}(x) = \frac{1}{B} \sum_b \hat{\tau}_b(x)$</span>
<span id="cb29-165"><a href="#cb29-165"></a></span>
<span id="cb29-166"><a href="#cb29-166"></a><span class="fu">## R Implementation with `grf`</span></span>
<span id="cb29-167"><a href="#cb29-167"></a></span>
<span id="cb29-170"><a href="#cb29-170"></a><span class="in">```{r}</span></span>
<span id="cb29-171"><a href="#cb29-171"></a><span class="co">#| label: causal-forest</span></span>
<span id="cb29-172"><a href="#cb29-172"></a><span class="co">#| fig-cap: "Causal forest recovers heterogeneous treatment effects"</span></span>
<span id="cb29-173"><a href="#cb29-173"></a><span class="co">#| eval: true</span></span>
<span id="cb29-174"><a href="#cb29-174"></a></span>
<span id="cb29-175"><a href="#cb29-175"></a><span class="fu">library</span>(grf)</span>
<span id="cb29-176"><a href="#cb29-176"></a></span>
<span id="cb29-177"><a href="#cb29-177"></a><span class="co"># Prepare data</span></span>
<span id="cb29-178"><a href="#cb29-178"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(X1, X2)</span>
<span id="cb29-179"><a href="#cb29-179"></a></span>
<span id="cb29-180"><a href="#cb29-180"></a><span class="co"># Fit causal forest</span></span>
<span id="cb29-181"><a href="#cb29-181"></a>cf <span class="ot">&lt;-</span> <span class="fu">causal_forest</span>(</span>
<span id="cb29-182"><a href="#cb29-182"></a>  <span class="at">X =</span> X,</span>
<span id="cb29-183"><a href="#cb29-183"></a>  <span class="at">Y =</span> Y,</span>
<span id="cb29-184"><a href="#cb29-184"></a>  <span class="at">W =</span> W,</span>
<span id="cb29-185"><a href="#cb29-185"></a>  <span class="at">num.trees =</span> <span class="dv">2000</span>,</span>
<span id="cb29-186"><a href="#cb29-186"></a>  <span class="at">honesty =</span> <span class="cn">TRUE</span>,           <span class="co"># honest splitting (default)</span></span>
<span id="cb29-187"><a href="#cb29-187"></a>  <span class="at">tune.parameters =</span> <span class="st">"all"</span>   <span class="co"># automatic hyperparameter tuning</span></span>
<span id="cb29-188"><a href="#cb29-188"></a>)</span>
<span id="cb29-189"><a href="#cb29-189"></a></span>
<span id="cb29-190"><a href="#cb29-190"></a><span class="co"># Predict treatment effects</span></span>
<span id="cb29-191"><a href="#cb29-191"></a>tau_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(cf)<span class="sc">$</span>predictions</span>
<span id="cb29-192"><a href="#cb29-192"></a></span>
<span id="cb29-193"><a href="#cb29-193"></a><span class="co"># Compare to truth</span></span>
<span id="cb29-194"><a href="#cb29-194"></a>comparison_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb29-195"><a href="#cb29-195"></a>  <span class="at">true =</span> tau_true,</span>
<span id="cb29-196"><a href="#cb29-196"></a>  <span class="at">estimated =</span> tau_hat,</span>
<span id="cb29-197"><a href="#cb29-197"></a>  <span class="at">X1 =</span> X1</span>
<span id="cb29-198"><a href="#cb29-198"></a>)</span>
<span id="cb29-199"><a href="#cb29-199"></a></span>
<span id="cb29-200"><a href="#cb29-200"></a><span class="co"># Scatter: estimated vs true</span></span>
<span id="cb29-201"><a href="#cb29-201"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(comparison_df, <span class="fu">aes</span>(<span class="at">x =</span> true, <span class="at">y =</span> estimated)) <span class="sc">+</span></span>
<span id="cb29-202"><a href="#cb29-202"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">color =</span> <span class="st">"#3498db"</span>) <span class="sc">+</span></span>
<span id="cb29-203"><a href="#cb29-203"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"#e74c3c"</span>) <span class="sc">+</span></span>
<span id="cb29-204"><a href="#cb29-204"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Estimated vs True CATE"</span>,</span>
<span id="cb29-205"><a href="#cb29-205"></a>       <span class="at">x =</span> <span class="st">"True τ(x)"</span>, <span class="at">y =</span> <span class="st">"Estimated τ̂(x)"</span>) <span class="sc">+</span></span>
<span id="cb29-206"><a href="#cb29-206"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb29-207"><a href="#cb29-207"></a></span>
<span id="cb29-208"><a href="#cb29-208"></a><span class="co"># By X1</span></span>
<span id="cb29-209"><a href="#cb29-209"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(comparison_df, <span class="fu">aes</span>(<span class="at">x =</span> X1)) <span class="sc">+</span></span>
<span id="cb29-210"><a href="#cb29-210"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> true), <span class="at">alpha =</span> <span class="fl">0.2</span>, <span class="at">color =</span> <span class="st">"#2ecc71"</span>) <span class="sc">+</span></span>
<span id="cb29-211"><a href="#cb29-211"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> estimated), <span class="at">alpha =</span> <span class="fl">0.2</span>, <span class="at">color =</span> <span class="st">"#3498db"</span>) <span class="sc">+</span></span>
<span id="cb29-212"><a href="#cb29-212"></a>  <span class="fu">geom_smooth</span>(<span class="fu">aes</span>(<span class="at">y =</span> estimated), <span class="at">method =</span> <span class="st">"loess"</span>, <span class="at">color =</span> <span class="st">"#e74c3c"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb29-213"><a href="#cb29-213"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"CATE by X₁"</span>,</span>
<span id="cb29-214"><a href="#cb29-214"></a>       <span class="at">subtitle =</span> <span class="st">"Green = true, Blue = estimated"</span>,</span>
<span id="cb29-215"><a href="#cb29-215"></a>       <span class="at">x =</span> <span class="fu">expression</span>(X[<span class="dv">1</span>]), <span class="at">y =</span> <span class="st">"Treatment Effect"</span>) <span class="sc">+</span></span>
<span id="cb29-216"><a href="#cb29-216"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb29-217"><a href="#cb29-217"></a></span>
<span id="cb29-218"><a href="#cb29-218"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(p1, p2, <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb29-219"><a href="#cb29-219"></a><span class="in">```</span></span>
<span id="cb29-220"><a href="#cb29-220"></a></span>
<span id="cb29-221"><a href="#cb29-221"></a><span class="fu">## Key `grf` Functions</span></span>
<span id="cb29-222"><a href="#cb29-222"></a></span>
<span id="cb29-223"><a href="#cb29-223"></a><span class="in">```r</span></span>
<span id="cb29-224"><a href="#cb29-224"></a><span class="fu">library</span>(grf)</span>
<span id="cb29-225"><a href="#cb29-225"></a></span>
<span id="cb29-226"><a href="#cb29-226"></a><span class="co"># Fit causal forest</span></span>
<span id="cb29-227"><a href="#cb29-227"></a>cf <span class="ot">&lt;-</span> <span class="fu">causal_forest</span>(X, Y, W, <span class="at">num.trees =</span> <span class="dv">2000</span>)</span>
<span id="cb29-228"><a href="#cb29-228"></a></span>
<span id="cb29-229"><a href="#cb29-229"></a><span class="co"># Point predictions</span></span>
<span id="cb29-230"><a href="#cb29-230"></a>tau_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(cf)<span class="sc">$</span>predictions</span>
<span id="cb29-231"><a href="#cb29-231"></a></span>
<span id="cb29-232"><a href="#cb29-232"></a><span class="co"># Predictions with variance (for CIs)</span></span>
<span id="cb29-233"><a href="#cb29-233"></a>tau_ci <span class="ot">&lt;-</span> <span class="fu">predict</span>(cf, <span class="at">estimate.variance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb29-234"><a href="#cb29-234"></a>lower <span class="ot">&lt;-</span> tau_ci<span class="sc">$</span>predictions <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> <span class="fu">sqrt</span>(tau_ci<span class="sc">$</span>variance.estimates)</span>
<span id="cb29-235"><a href="#cb29-235"></a>upper <span class="ot">&lt;-</span> tau_ci<span class="sc">$</span>predictions <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> <span class="fu">sqrt</span>(tau_ci<span class="sc">$</span>variance.estimates)</span>
<span id="cb29-236"><a href="#cb29-236"></a></span>
<span id="cb29-237"><a href="#cb29-237"></a><span class="co"># Average treatment effect with SE</span></span>
<span id="cb29-238"><a href="#cb29-238"></a>ate <span class="ot">&lt;-</span> <span class="fu">average_treatment_effect</span>(cf, <span class="at">target.sample =</span> <span class="st">"all"</span>)</span>
<span id="cb29-239"><a href="#cb29-239"></a><span class="fu">cat</span>(<span class="st">"ATE:"</span>, ate[<span class="dv">1</span>], <span class="st">"SE:"</span>, ate[<span class="dv">2</span>], <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb29-240"><a href="#cb29-240"></a></span>
<span id="cb29-241"><a href="#cb29-241"></a><span class="co"># ATT</span></span>
<span id="cb29-242"><a href="#cb29-242"></a>att <span class="ot">&lt;-</span> <span class="fu">average_treatment_effect</span>(cf, <span class="at">target.sample =</span> <span class="st">"treated"</span>)</span>
<span id="cb29-243"><a href="#cb29-243"></a></span>
<span id="cb29-244"><a href="#cb29-244"></a><span class="co"># Variable importance: which X drive heterogeneity?</span></span>
<span id="cb29-245"><a href="#cb29-245"></a>vi <span class="ot">&lt;-</span> <span class="fu">variable_importance</span>(cf)</span>
<span id="cb29-246"><a href="#cb29-246"></a></span>
<span id="cb29-247"><a href="#cb29-247"></a><span class="co"># Best linear projection: linear approximation of τ(x)</span></span>
<span id="cb29-248"><a href="#cb29-248"></a>blp <span class="ot">&lt;-</span> <span class="fu">best_linear_projection</span>(cf, X)</span>
<span id="cb29-249"><a href="#cb29-249"></a></span>
<span id="cb29-250"><a href="#cb29-250"></a><span class="co"># Calibration test: is there heterogeneity?</span></span>
<span id="cb29-251"><a href="#cb29-251"></a><span class="fu">test_calibration</span>(cf)</span>
<span id="cb29-252"><a href="#cb29-252"></a><span class="in">```</span></span>
<span id="cb29-253"><a href="#cb29-253"></a></span>
<span id="cb29-254"><a href="#cb29-254"></a><span class="fu">## Variable Importance</span></span>
<span id="cb29-255"><a href="#cb29-255"></a></span>
<span id="cb29-256"><a href="#cb29-256"></a>Which covariates drive treatment effect heterogeneity?</span>
<span id="cb29-257"><a href="#cb29-257"></a></span>
<span id="cb29-260"><a href="#cb29-260"></a><span class="in">```{r}</span></span>
<span id="cb29-261"><a href="#cb29-261"></a><span class="co">#| label: variable-importance</span></span>
<span id="cb29-262"><a href="#cb29-262"></a><span class="co">#| fig-cap: "Variable importance identifies X₁ as driver of heterogeneity"</span></span>
<span id="cb29-263"><a href="#cb29-263"></a><span class="co">#| eval: true</span></span>
<span id="cb29-264"><a href="#cb29-264"></a></span>
<span id="cb29-265"><a href="#cb29-265"></a><span class="co"># Variable importance</span></span>
<span id="cb29-266"><a href="#cb29-266"></a>vi <span class="ot">&lt;-</span> <span class="fu">variable_importance</span>(cf)</span>
<span id="cb29-267"><a href="#cb29-267"></a>vi_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb29-268"><a href="#cb29-268"></a>  <span class="at">variable =</span> <span class="fu">c</span>(<span class="st">"X1"</span>, <span class="st">"X2"</span>),</span>
<span id="cb29-269"><a href="#cb29-269"></a>  <span class="at">importance =</span> vi</span>
<span id="cb29-270"><a href="#cb29-270"></a>)</span>
<span id="cb29-271"><a href="#cb29-271"></a></span>
<span id="cb29-272"><a href="#cb29-272"></a><span class="fu">ggplot</span>(vi_df, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(variable, importance), <span class="at">y =</span> importance)) <span class="sc">+</span></span>
<span id="cb29-273"><a href="#cb29-273"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="at">fill =</span> <span class="st">"#3498db"</span>) <span class="sc">+</span></span>
<span id="cb29-274"><a href="#cb29-274"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb29-275"><a href="#cb29-275"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Variable Importance for Treatment Heterogeneity"</span>,</span>
<span id="cb29-276"><a href="#cb29-276"></a>       <span class="at">subtitle =</span> <span class="st">"X₁ drives heterogeneity (as designed)"</span>,</span>
<span id="cb29-277"><a href="#cb29-277"></a>       <span class="at">x =</span> <span class="cn">NULL</span>, <span class="at">y =</span> <span class="st">"Importance"</span>) <span class="sc">+</span></span>
<span id="cb29-278"><a href="#cb29-278"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb29-279"><a href="#cb29-279"></a><span class="in">```</span></span>
<span id="cb29-280"><a href="#cb29-280"></a></span>
<span id="cb29-281"><a href="#cb29-281"></a><span class="fu">## Observational Data: Pre-Estimated Nuisance Functions</span></span>
<span id="cb29-282"><a href="#cb29-282"></a></span>
<span id="cb29-283"><a href="#cb29-283"></a>For observational studies, pre-fit propensity and outcome models:</span>
<span id="cb29-284"><a href="#cb29-284"></a></span>
<span id="cb29-285"><a href="#cb29-285"></a><span class="in">```r</span></span>
<span id="cb29-286"><a href="#cb29-286"></a><span class="co"># Pre-fit nuisance models (recommended for observational data)</span></span>
<span id="cb29-287"><a href="#cb29-287"></a>W.hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(<span class="fu">regression_forest</span>(X, W))<span class="sc">$</span>predictions  <span class="co"># propensity</span></span>
<span id="cb29-288"><a href="#cb29-288"></a>Y.hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(<span class="fu">regression_forest</span>(X, Y))<span class="sc">$</span>predictions  <span class="co"># outcome</span></span>
<span id="cb29-289"><a href="#cb29-289"></a></span>
<span id="cb29-290"><a href="#cb29-290"></a><span class="co"># Causal forest with pre-estimated nuisance</span></span>
<span id="cb29-291"><a href="#cb29-291"></a>cf_obs <span class="ot">&lt;-</span> <span class="fu">causal_forest</span>(X, Y, W, <span class="at">W.hat =</span> W.hat, <span class="at">Y.hat =</span> Y.hat)</span>
<span id="cb29-292"><a href="#cb29-292"></a><span class="in">```</span></span>
<span id="cb29-293"><a href="#cb29-293"></a></span>
<span id="cb29-294"><a href="#cb29-294"></a><span class="fu"># Double/Debiased Machine Learning {.unnumbered}</span></span>
<span id="cb29-295"><a href="#cb29-295"></a></span>
<span id="cb29-296"><a href="#cb29-296"></a><span class="fu">## The Problem</span></span>
<span id="cb29-297"><a href="#cb29-297"></a></span>
<span id="cb29-298"><a href="#cb29-298"></a>When using ML for nuisance parameters (propensity score, outcome model), regularization introduces bias that **invalidates standard inference**.</span>
<span id="cb29-299"><a href="#cb29-299"></a></span>
<span id="cb29-300"><a href="#cb29-300"></a>**Example**: LASSO shrinks coefficients → biased treatment effect → invalid t-statistics.</span>
<span id="cb29-301"><a href="#cb29-301"></a></span>
<span id="cb29-302"><a href="#cb29-302"></a><span class="fu">## The Solution (Chernozhukov et al. 2018)</span></span>
<span id="cb29-303"><a href="#cb29-303"></a></span>
<span id="cb29-304"><a href="#cb29-304"></a>Two key ingredients:</span>
<span id="cb29-305"><a href="#cb29-305"></a></span>
<span id="cb29-306"><a href="#cb29-306"></a><span class="ss">1. </span>**Cross-fitting**: Train ML on fold $-k$, predict on fold $k$</span>
<span id="cb29-307"><a href="#cb29-307"></a><span class="ss">2. </span>**Neyman orthogonality**: Use score function robust to nuisance estimation error</span>
<span id="cb29-308"><a href="#cb29-308"></a></span>
<span id="cb29-309"><a href="#cb29-309"></a><span class="fu">## Partially Linear Model</span></span>
<span id="cb29-310"><a href="#cb29-310"></a></span>
<span id="cb29-311"><a href="#cb29-311"></a>$$</span>
<span id="cb29-312"><a href="#cb29-312"></a>Y = \theta D + g(X) + U, \quad \mathbb{E}<span class="co">[</span><span class="ot">U|X,D</span><span class="co">]</span> = 0</span>
<span id="cb29-313"><a href="#cb29-313"></a>$$</span>
<span id="cb29-314"><a href="#cb29-314"></a>$$</span>
<span id="cb29-315"><a href="#cb29-315"></a>D = m(X) + V, \quad \mathbb{E}<span class="co">[</span><span class="ot">V|X</span><span class="co">]</span> = 0</span>
<span id="cb29-316"><a href="#cb29-316"></a>$$</span>
<span id="cb29-317"><a href="#cb29-317"></a></span>
<span id="cb29-318"><a href="#cb29-318"></a>**Target**: $\theta$ (treatment effect)</span>
<span id="cb29-319"><a href="#cb29-319"></a></span>
<span id="cb29-320"><a href="#cb29-320"></a>**Nuisance**: $g(X)$ (outcome confounding), $m(X)$ (propensity/treatment model)</span>
<span id="cb29-321"><a href="#cb29-321"></a></span>
<span id="cb29-322"><a href="#cb29-322"></a><span class="fu">## The Algorithm</span></span>
<span id="cb29-323"><a href="#cb29-323"></a></span>
<span id="cb29-324"><a href="#cb29-324"></a><span class="ss">1. </span>Split data into $K$ folds (typically $K = 5$)</span>
<span id="cb29-325"><a href="#cb29-325"></a><span class="ss">2. </span>For each fold $k$:</span>
<span id="cb29-326"><a href="#cb29-326"></a><span class="ss">   - </span>Train $\hat{g}_{-k}(X)$ and $\hat{m}_{-k}(X)$ on all other folds</span>
<span id="cb29-327"><a href="#cb29-327"></a><span class="ss">   - </span>Compute residuals on fold $k$:</span>
<span id="cb29-328"><a href="#cb29-328"></a><span class="ss">     - </span>$\tilde{Y}_i = Y_i - \hat{g}_{-k}(X_i)$</span>
<span id="cb29-329"><a href="#cb29-329"></a><span class="ss">     - </span>$\tilde{D}_i = D_i - \hat{m}_{-k}(X_i)$</span>
<span id="cb29-330"><a href="#cb29-330"></a><span class="ss">3. </span>Estimate: $\hat{\theta} = \frac{\sum_i \tilde{D}_i \tilde{Y}_i}{\sum_i \tilde{D}_i^2}$</span>
<span id="cb29-331"><a href="#cb29-331"></a><span class="ss">4. </span>Standard error: standard OLS formula on residualized data</span>
<span id="cb29-332"><a href="#cb29-332"></a></span>
<span id="cb29-333"><a href="#cb29-333"></a><span class="fu">## Why It Works: Orthogonality</span></span>
<span id="cb29-334"><a href="#cb29-334"></a></span>
<span id="cb29-335"><a href="#cb29-335"></a>The **orthogonal moment condition**:</span>
<span id="cb29-336"><a href="#cb29-336"></a>$$</span>
<span id="cb29-337"><a href="#cb29-337"></a>\psi(W; \theta, \eta) = (Y - g(X) - \theta D)(D - m(X))</span>
<span id="cb29-338"><a href="#cb29-338"></a>$$</span>
<span id="cb29-339"><a href="#cb29-339"></a></span>
<span id="cb29-340"><a href="#cb29-340"></a>has the property that small errors in $\hat{g}, \hat{m}$ don't bias $\hat{\theta}$:</span>
<span id="cb29-341"><a href="#cb29-341"></a>$$</span>
<span id="cb29-342"><a href="#cb29-342"></a>\frac{\partial}{\partial \eta} \mathbb{E}<span class="co">[</span><span class="ot">\psi(W; \theta_0, \eta)</span><span class="co">]</span> \bigg|_{\eta = \eta_0} = 0</span>
<span id="cb29-343"><a href="#cb29-343"></a>$$</span>
<span id="cb29-344"><a href="#cb29-344"></a></span>
<span id="cb29-345"><a href="#cb29-345"></a><span class="fu">## Python Implementation with `doubleml`</span></span>
<span id="cb29-346"><a href="#cb29-346"></a></span>
<span id="cb29-347"><a href="#cb29-347"></a><span class="in">```python</span></span>
<span id="cb29-348"><a href="#cb29-348"></a><span class="co"># Double ML estimation in Python</span></span>
<span id="cb29-349"><a href="#cb29-349"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb29-350"><a href="#cb29-350"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_predict</span>
<span id="cb29-351"><a href="#cb29-351"></a><span class="im">import</span> warnings</span>
<span id="cb29-352"><a href="#cb29-352"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb29-353"><a href="#cb29-353"></a></span>
<span id="cb29-354"><a href="#cb29-354"></a><span class="co"># Simulate data</span></span>
<span id="cb29-355"><a href="#cb29-355"></a>n <span class="op">=</span> <span class="dv">2000</span></span>
<span id="cb29-356"><a href="#cb29-356"></a>p <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb29-357"><a href="#cb29-357"></a>X <span class="op">=</span> np.random.randn(n, p)</span>
<span id="cb29-358"><a href="#cb29-358"></a>theta_true <span class="op">=</span> <span class="fl">0.5</span>  <span class="co"># true treatment effect</span></span>
<span id="cb29-359"><a href="#cb29-359"></a>D <span class="op">=</span> X[:, <span class="dv">0</span>] <span class="op">+</span> <span class="fl">0.5</span> <span class="op">*</span> X[:, <span class="dv">1</span>] <span class="op">+</span> np.random.randn(n)  <span class="co"># treatment depends on X</span></span>
<span id="cb29-360"><a href="#cb29-360"></a>Y <span class="op">=</span> theta_true <span class="op">*</span> D <span class="op">+</span> X[:, <span class="dv">0</span>] <span class="op">+</span> X[:, <span class="dv">1</span>] <span class="op">+</span> np.random.randn(n)  <span class="co"># outcome</span></span>
<span id="cb29-361"><a href="#cb29-361"></a></span>
<span id="cb29-362"><a href="#cb29-362"></a><span class="co"># Manual Double ML</span></span>
<span id="cb29-363"><a href="#cb29-363"></a><span class="kw">def</span> double_ml_plr(Y, D, X, K<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb29-364"><a href="#cb29-364"></a>    <span class="co">"""</span></span>
<span id="cb29-365"><a href="#cb29-365"></a><span class="co">    Double ML for Partially Linear Regression</span></span>
<span id="cb29-366"><a href="#cb29-366"></a><span class="co">    Y = theta * D + g(X) + U</span></span>
<span id="cb29-367"><a href="#cb29-367"></a><span class="co">    D = m(X) + V</span></span>
<span id="cb29-368"><a href="#cb29-368"></a><span class="co">    """</span></span>
<span id="cb29-369"><a href="#cb29-369"></a>    n <span class="op">=</span> <span class="bu">len</span>(Y)</span>
<span id="cb29-370"><a href="#cb29-370"></a></span>
<span id="cb29-371"><a href="#cb29-371"></a>    <span class="co"># Cross-fitted predictions</span></span>
<span id="cb29-372"><a href="#cb29-372"></a>    g_hat <span class="op">=</span> cross_val_predict(</span>
<span id="cb29-373"><a href="#cb29-373"></a>        RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, max_depth<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>),</span>
<span id="cb29-374"><a href="#cb29-374"></a>        X, Y, cv<span class="op">=</span>K</span>
<span id="cb29-375"><a href="#cb29-375"></a>    )</span>
<span id="cb29-376"><a href="#cb29-376"></a>    m_hat <span class="op">=</span> cross_val_predict(</span>
<span id="cb29-377"><a href="#cb29-377"></a>        RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, max_depth<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>),</span>
<span id="cb29-378"><a href="#cb29-378"></a>        X, D, cv<span class="op">=</span>K</span>
<span id="cb29-379"><a href="#cb29-379"></a>    )</span>
<span id="cb29-380"><a href="#cb29-380"></a></span>
<span id="cb29-381"><a href="#cb29-381"></a>    <span class="co"># Residualize</span></span>
<span id="cb29-382"><a href="#cb29-382"></a>    Y_tilde <span class="op">=</span> Y <span class="op">-</span> g_hat</span>
<span id="cb29-383"><a href="#cb29-383"></a>    D_tilde <span class="op">=</span> D <span class="op">-</span> m_hat</span>
<span id="cb29-384"><a href="#cb29-384"></a></span>
<span id="cb29-385"><a href="#cb29-385"></a>    <span class="co"># Estimate theta</span></span>
<span id="cb29-386"><a href="#cb29-386"></a>    theta_hat <span class="op">=</span> np.<span class="bu">sum</span>(D_tilde <span class="op">*</span> Y_tilde) <span class="op">/</span> np.<span class="bu">sum</span>(D_tilde <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb29-387"><a href="#cb29-387"></a></span>
<span id="cb29-388"><a href="#cb29-388"></a>    <span class="co"># Standard error</span></span>
<span id="cb29-389"><a href="#cb29-389"></a>    residuals <span class="op">=</span> Y_tilde <span class="op">-</span> theta_hat <span class="op">*</span> D_tilde</span>
<span id="cb29-390"><a href="#cb29-390"></a>    se_hat <span class="op">=</span> np.sqrt(np.<span class="bu">sum</span>(residuals <span class="op">**</span> <span class="dv">2</span> <span class="op">*</span> D_tilde <span class="op">**</span> <span class="dv">2</span>) <span class="op">/</span> (np.<span class="bu">sum</span>(D_tilde <span class="op">**</span> <span class="dv">2</span>) <span class="op">**</span> <span class="dv">2</span>))</span>
<span id="cb29-391"><a href="#cb29-391"></a></span>
<span id="cb29-392"><a href="#cb29-392"></a>    <span class="cf">return</span> {</span>
<span id="cb29-393"><a href="#cb29-393"></a>        <span class="st">'estimate'</span>: theta_hat,</span>
<span id="cb29-394"><a href="#cb29-394"></a>        <span class="st">'se'</span>: se_hat,</span>
<span id="cb29-395"><a href="#cb29-395"></a>        <span class="st">'ci_lower'</span>: theta_hat <span class="op">-</span> <span class="fl">1.96</span> <span class="op">*</span> se_hat,</span>
<span id="cb29-396"><a href="#cb29-396"></a>        <span class="st">'ci_upper'</span>: theta_hat <span class="op">+</span> <span class="fl">1.96</span> <span class="op">*</span> se_hat</span>
<span id="cb29-397"><a href="#cb29-397"></a>    }</span>
<span id="cb29-398"><a href="#cb29-398"></a></span>
<span id="cb29-399"><a href="#cb29-399"></a><span class="co"># Run Double ML</span></span>
<span id="cb29-400"><a href="#cb29-400"></a>result <span class="op">=</span> double_ml_plr(Y, D, X)</span>
<span id="cb29-401"><a href="#cb29-401"></a></span>
<span id="cb29-402"><a href="#cb29-402"></a><span class="bu">print</span>(<span class="ss">f"True θ: </span><span class="sc">{</span>theta_true<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb29-403"><a href="#cb29-403"></a><span class="bu">print</span>(<span class="ss">f"Double ML estimate: </span><span class="sc">{</span>result[<span class="st">'estimate'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb29-404"><a href="#cb29-404"></a><span class="bu">print</span>(<span class="ss">f"Standard error: </span><span class="sc">{</span>result[<span class="st">'se'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb29-405"><a href="#cb29-405"></a><span class="bu">print</span>(<span class="ss">f"95% CI: [</span><span class="sc">{</span>result[<span class="st">'ci_lower'</span>]<span class="sc">:.4f}</span><span class="ss">, </span><span class="sc">{</span>result[<span class="st">'ci_upper'</span>]<span class="sc">:.4f}</span><span class="ss">]"</span>)</span>
<span id="cb29-406"><a href="#cb29-406"></a><span class="in">```</span></span>
<span id="cb29-407"><a href="#cb29-407"></a></span>
<span id="cb29-408"><a href="#cb29-408"></a><span class="fu">## Using the `DoubleML` Package</span></span>
<span id="cb29-409"><a href="#cb29-409"></a></span>
<span id="cb29-410"><a href="#cb29-410"></a><span class="in">```python</span></span>
<span id="cb29-411"><a href="#cb29-411"></a><span class="im">from</span> doubleml <span class="im">import</span> DoubleMLPLR, DoubleMLData</span>
<span id="cb29-412"><a href="#cb29-412"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb29-413"><a href="#cb29-413"></a></span>
<span id="cb29-414"><a href="#cb29-414"></a><span class="co"># Create data object</span></span>
<span id="cb29-415"><a href="#cb29-415"></a>df <span class="op">=</span> pd.DataFrame(X, columns<span class="op">=</span>[<span class="ss">f'X</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(p)])</span>
<span id="cb29-416"><a href="#cb29-416"></a>df[<span class="st">'Y'</span>] <span class="op">=</span> Y</span>
<span id="cb29-417"><a href="#cb29-417"></a>df[<span class="st">'D'</span>] <span class="op">=</span> D</span>
<span id="cb29-418"><a href="#cb29-418"></a></span>
<span id="cb29-419"><a href="#cb29-419"></a>dml_data <span class="op">=</span> DoubleMLData(</span>
<span id="cb29-420"><a href="#cb29-420"></a>    df, y_col<span class="op">=</span><span class="st">'Y'</span>, d_cols<span class="op">=</span><span class="st">'D'</span>,</span>
<span id="cb29-421"><a href="#cb29-421"></a>    x_cols<span class="op">=</span>[<span class="ss">f'X</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(p)]</span>
<span id="cb29-422"><a href="#cb29-422"></a>)</span>
<span id="cb29-423"><a href="#cb29-423"></a></span>
<span id="cb29-424"><a href="#cb29-424"></a><span class="co"># Specify learners</span></span>
<span id="cb29-425"><a href="#cb29-425"></a>ml_l <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">500</span>, max_depth<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb29-426"><a href="#cb29-426"></a>ml_m <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">500</span>, max_depth<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb29-427"><a href="#cb29-427"></a></span>
<span id="cb29-428"><a href="#cb29-428"></a><span class="co"># Fit</span></span>
<span id="cb29-429"><a href="#cb29-429"></a>dml_plr <span class="op">=</span> DoubleMLPLR(dml_data, ml_l, ml_m, n_folds<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb29-430"><a href="#cb29-430"></a>dml_plr.fit()</span>
<span id="cb29-431"><a href="#cb29-431"></a><span class="bu">print</span>(dml_plr.summary)</span>
<span id="cb29-432"><a href="#cb29-432"></a><span class="in">```</span></span>
<span id="cb29-433"><a href="#cb29-433"></a></span>
<span id="cb29-434"><a href="#cb29-434"></a><span class="fu">## R Implementation</span></span>
<span id="cb29-435"><a href="#cb29-435"></a></span>
<span id="cb29-438"><a href="#cb29-438"></a><span class="in">```{r}</span></span>
<span id="cb29-439"><a href="#cb29-439"></a><span class="co">#| label: double-ml-r</span></span>
<span id="cb29-440"><a href="#cb29-440"></a><span class="co">#| fig-cap: "Double ML estimation in R"</span></span>
<span id="cb29-441"><a href="#cb29-441"></a><span class="co">#| eval: true</span></span>
<span id="cb29-442"><a href="#cb29-442"></a></span>
<span id="cb29-443"><a href="#cb29-443"></a><span class="co"># Manual Double ML for ATE (binary treatment)</span></span>
<span id="cb29-444"><a href="#cb29-444"></a>double_ml_ate <span class="ot">&lt;-</span> <span class="cf">function</span>(Y, W, X, <span class="at">K =</span> <span class="dv">5</span>) {</span>
<span id="cb29-445"><a href="#cb29-445"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(Y)</span>
<span id="cb29-446"><a href="#cb29-446"></a>  folds <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span>K, <span class="at">length.out =</span> n))</span>
<span id="cb29-447"><a href="#cb29-447"></a></span>
<span id="cb29-448"><a href="#cb29-448"></a>  psi <span class="ot">&lt;-</span> <span class="fu">numeric</span>(n)</span>
<span id="cb29-449"><a href="#cb29-449"></a></span>
<span id="cb29-450"><a href="#cb29-450"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>K) {</span>
<span id="cb29-451"><a href="#cb29-451"></a>    train_idx <span class="ot">&lt;-</span> folds <span class="sc">!=</span> k</span>
<span id="cb29-452"><a href="#cb29-452"></a>    test_idx <span class="ot">&lt;-</span> folds <span class="sc">==</span> k</span>
<span id="cb29-453"><a href="#cb29-453"></a></span>
<span id="cb29-454"><a href="#cb29-454"></a>    <span class="co"># Train outcome models (T-learner style)</span></span>
<span id="cb29-455"><a href="#cb29-455"></a>    rf_1 <span class="ot">&lt;-</span> grf<span class="sc">::</span><span class="fu">regression_forest</span>(X[train_idx <span class="sc">&amp;</span> W <span class="sc">==</span> <span class="dv">1</span>, , <span class="at">drop =</span> <span class="cn">FALSE</span>],</span>
<span id="cb29-456"><a href="#cb29-456"></a>                                    Y[train_idx <span class="sc">&amp;</span> W <span class="sc">==</span> <span class="dv">1</span>])</span>
<span id="cb29-457"><a href="#cb29-457"></a>    rf_0 <span class="ot">&lt;-</span> grf<span class="sc">::</span><span class="fu">regression_forest</span>(X[train_idx <span class="sc">&amp;</span> W <span class="sc">==</span> <span class="dv">0</span>, , <span class="at">drop =</span> <span class="cn">FALSE</span>],</span>
<span id="cb29-458"><a href="#cb29-458"></a>                                    Y[train_idx <span class="sc">&amp;</span> W <span class="sc">==</span> <span class="dv">0</span>])</span>
<span id="cb29-459"><a href="#cb29-459"></a></span>
<span id="cb29-460"><a href="#cb29-460"></a>    <span class="co"># Train propensity model</span></span>
<span id="cb29-461"><a href="#cb29-461"></a>    rf_e <span class="ot">&lt;-</span> grf<span class="sc">::</span><span class="fu">regression_forest</span>(X[train_idx, , <span class="at">drop =</span> <span class="cn">FALSE</span>],</span>
<span id="cb29-462"><a href="#cb29-462"></a>                                    W[train_idx])</span>
<span id="cb29-463"><a href="#cb29-463"></a></span>
<span id="cb29-464"><a href="#cb29-464"></a>    <span class="co"># Predict on test fold</span></span>
<span id="cb29-465"><a href="#cb29-465"></a>    mu1_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_1, X[test_idx, , <span class="at">drop =</span> <span class="cn">FALSE</span>])<span class="sc">$</span>predictions</span>
<span id="cb29-466"><a href="#cb29-466"></a>    mu0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_0, X[test_idx, , <span class="at">drop =</span> <span class="cn">FALSE</span>])<span class="sc">$</span>predictions</span>
<span id="cb29-467"><a href="#cb29-467"></a>    e_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_e, X[test_idx, , <span class="at">drop =</span> <span class="cn">FALSE</span>])<span class="sc">$</span>predictions</span>
<span id="cb29-468"><a href="#cb29-468"></a>    e_hat <span class="ot">&lt;-</span> <span class="fu">pmax</span>(<span class="fu">pmin</span>(e_hat, <span class="fl">0.99</span>), <span class="fl">0.01</span>)  <span class="co"># clip propensity</span></span>
<span id="cb29-469"><a href="#cb29-469"></a></span>
<span id="cb29-470"><a href="#cb29-470"></a>    <span class="co"># AIPW pseudo-outcome (doubly robust)</span></span>
<span id="cb29-471"><a href="#cb29-471"></a>    Y_test <span class="ot">&lt;-</span> Y[test_idx]</span>
<span id="cb29-472"><a href="#cb29-472"></a>    W_test <span class="ot">&lt;-</span> W[test_idx]</span>
<span id="cb29-473"><a href="#cb29-473"></a></span>
<span id="cb29-474"><a href="#cb29-474"></a>    psi[test_idx] <span class="ot">&lt;-</span> W_test <span class="sc">*</span> (Y_test <span class="sc">-</span> mu1_hat) <span class="sc">/</span> e_hat <span class="sc">-</span></span>
<span id="cb29-475"><a href="#cb29-475"></a>                     (<span class="dv">1</span> <span class="sc">-</span> W_test) <span class="sc">*</span> (Y_test <span class="sc">-</span> mu0_hat) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> e_hat) <span class="sc">+</span></span>
<span id="cb29-476"><a href="#cb29-476"></a>                     mu1_hat <span class="sc">-</span> mu0_hat</span>
<span id="cb29-477"><a href="#cb29-477"></a>  }</span>
<span id="cb29-478"><a href="#cb29-478"></a></span>
<span id="cb29-479"><a href="#cb29-479"></a>  <span class="co"># ATE and SE</span></span>
<span id="cb29-480"><a href="#cb29-480"></a>  tau_hat <span class="ot">&lt;-</span> <span class="fu">mean</span>(psi)</span>
<span id="cb29-481"><a href="#cb29-481"></a>  se_hat <span class="ot">&lt;-</span> <span class="fu">sd</span>(psi) <span class="sc">/</span> <span class="fu">sqrt</span>(n)</span>
<span id="cb29-482"><a href="#cb29-482"></a></span>
<span id="cb29-483"><a href="#cb29-483"></a>  <span class="fu">list</span>(</span>
<span id="cb29-484"><a href="#cb29-484"></a>    <span class="at">estimate =</span> tau_hat,</span>
<span id="cb29-485"><a href="#cb29-485"></a>    <span class="at">se =</span> se_hat,</span>
<span id="cb29-486"><a href="#cb29-486"></a>    <span class="at">ci_lower =</span> tau_hat <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> se_hat,</span>
<span id="cb29-487"><a href="#cb29-487"></a>    <span class="at">ci_upper =</span> tau_hat <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> se_hat</span>
<span id="cb29-488"><a href="#cb29-488"></a>  )</span>
<span id="cb29-489"><a href="#cb29-489"></a>}</span>
<span id="cb29-490"><a href="#cb29-490"></a></span>
<span id="cb29-491"><a href="#cb29-491"></a><span class="co"># Apply</span></span>
<span id="cb29-492"><a href="#cb29-492"></a>dml_result <span class="ot">&lt;-</span> <span class="fu">double_ml_ate</span>(Y, W, <span class="fu">as.matrix</span>(<span class="fu">cbind</span>(X1, X2)))</span>
<span id="cb29-493"><a href="#cb29-493"></a>true_ate <span class="ot">&lt;-</span> <span class="fu">mean</span>(tau_true)</span>
<span id="cb29-494"><a href="#cb29-494"></a></span>
<span id="cb29-495"><a href="#cb29-495"></a><span class="fu">cat</span>(<span class="st">"Double ML ATE:"</span>, <span class="fu">round</span>(dml_result<span class="sc">$</span>estimate, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb29-496"><a href="#cb29-496"></a><span class="fu">cat</span>(<span class="st">"SE:"</span>, <span class="fu">round</span>(dml_result<span class="sc">$</span>se, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb29-497"><a href="#cb29-497"></a><span class="fu">cat</span>(<span class="st">"True ATE:"</span>, <span class="fu">round</span>(true_ate, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb29-498"><a href="#cb29-498"></a><span class="fu">cat</span>(<span class="st">"95% CI: ["</span>, <span class="fu">round</span>(dml_result<span class="sc">$</span>ci_lower, <span class="dv">3</span>), <span class="st">","</span>,</span>
<span id="cb29-499"><a href="#cb29-499"></a>    <span class="fu">round</span>(dml_result<span class="sc">$</span>ci_upper, <span class="dv">3</span>), <span class="st">"]</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb29-500"><a href="#cb29-500"></a><span class="in">```</span></span>
<span id="cb29-501"><a href="#cb29-501"></a></span>
<span id="cb29-502"><a href="#cb29-502"></a><span class="fu"># Meta-Learners {.unnumbered}</span></span>
<span id="cb29-503"><a href="#cb29-503"></a></span>
<span id="cb29-504"><a href="#cb29-504"></a><span class="fu">## Overview</span></span>
<span id="cb29-505"><a href="#cb29-505"></a></span>
<span id="cb29-506"><a href="#cb29-506"></a>Meta-learners are strategies for combining base ML models to estimate CATE.</span>
<span id="cb29-507"><a href="#cb29-507"></a></span>
<span id="cb29-508"><a href="#cb29-508"></a><span class="fu">## T-Learner (Two Models)</span></span>
<span id="cb29-509"><a href="#cb29-509"></a></span>
<span id="cb29-510"><a href="#cb29-510"></a>Train **separate** models for treatment and control:</span>
<span id="cb29-511"><a href="#cb29-511"></a></span>
<span id="cb29-512"><a href="#cb29-512"></a>$$</span>
<span id="cb29-513"><a href="#cb29-513"></a>\hat{\tau}(x) = \hat{\mu}_1(x) - \hat{\mu}_0(x)</span>
<span id="cb29-514"><a href="#cb29-514"></a>$$</span>
<span id="cb29-515"><a href="#cb29-515"></a></span>
<span id="cb29-516"><a href="#cb29-516"></a><span class="in">```python</span></span>
<span id="cb29-517"><a href="#cb29-517"></a><span class="co"># T-Learner implementation</span></span>
<span id="cb29-518"><a href="#cb29-518"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb29-519"><a href="#cb29-519"></a></span>
<span id="cb29-520"><a href="#cb29-520"></a><span class="co"># Binary treatment simulation</span></span>
<span id="cb29-521"><a href="#cb29-521"></a>n <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb29-522"><a href="#cb29-522"></a>X_sim <span class="op">=</span> np.random.randn(n, <span class="dv">5</span>)</span>
<span id="cb29-523"><a href="#cb29-523"></a>W_sim <span class="op">=</span> np.random.binomial(<span class="dv">1</span>, <span class="fl">0.5</span>, n)</span>
<span id="cb29-524"><a href="#cb29-524"></a>tau_sim <span class="op">=</span> X_sim[:, <span class="dv">0</span>] <span class="op">+</span> <span class="fl">0.5</span> <span class="op">*</span> X_sim[:, <span class="dv">1</span>]</span>
<span id="cb29-525"><a href="#cb29-525"></a>Y_sim <span class="op">=</span> tau_sim <span class="op">*</span> W_sim <span class="op">+</span> X_sim[:, <span class="dv">0</span>] <span class="op">+</span> np.random.randn(n)</span>
<span id="cb29-526"><a href="#cb29-526"></a></span>
<span id="cb29-527"><a href="#cb29-527"></a><span class="co"># T-Learner: separate models for treatment and control</span></span>
<span id="cb29-528"><a href="#cb29-528"></a>model_0 <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb29-529"><a href="#cb29-529"></a>model_1 <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb29-530"><a href="#cb29-530"></a></span>
<span id="cb29-531"><a href="#cb29-531"></a>model_0.fit(X_sim[W_sim <span class="op">==</span> <span class="dv">0</span>], Y_sim[W_sim <span class="op">==</span> <span class="dv">0</span>])</span>
<span id="cb29-532"><a href="#cb29-532"></a>model_1.fit(X_sim[W_sim <span class="op">==</span> <span class="dv">1</span>], Y_sim[W_sim <span class="op">==</span> <span class="dv">1</span>])</span>
<span id="cb29-533"><a href="#cb29-533"></a></span>
<span id="cb29-534"><a href="#cb29-534"></a>tau_t <span class="op">=</span> model_1.predict(X_sim) <span class="op">-</span> model_0.predict(X_sim)</span>
<span id="cb29-535"><a href="#cb29-535"></a></span>
<span id="cb29-536"><a href="#cb29-536"></a><span class="bu">print</span>(<span class="ss">f"T-Learner correlation with true τ: </span><span class="sc">{</span>np<span class="sc">.</span>corrcoef(tau_sim, tau_t)[<span class="dv">0</span>,<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb29-537"><a href="#cb29-537"></a><span class="in">```</span></span>
<span id="cb29-538"><a href="#cb29-538"></a></span>
<span id="cb29-539"><a href="#cb29-539"></a>**Pros**: Simple, no propensity needed</span>
<span id="cb29-540"><a href="#cb29-540"></a></span>
<span id="cb29-541"><a href="#cb29-541"></a>**Cons**: High variance, especially with imbalanced treatment</span>
<span id="cb29-542"><a href="#cb29-542"></a></span>
<span id="cb29-543"><a href="#cb29-543"></a><span class="fu">## S-Learner (Single Model)</span></span>
<span id="cb29-544"><a href="#cb29-544"></a></span>
<span id="cb29-545"><a href="#cb29-545"></a>Single model with treatment as feature:</span>
<span id="cb29-546"><a href="#cb29-546"></a></span>
<span id="cb29-547"><a href="#cb29-547"></a>$$</span>
<span id="cb29-548"><a href="#cb29-548"></a>\hat{\mu}(x, w) \rightarrow \hat{\tau}(x) = \hat{\mu}(x, 1) - \hat{\mu}(x, 0)</span>
<span id="cb29-549"><a href="#cb29-549"></a>$$</span>
<span id="cb29-550"><a href="#cb29-550"></a></span>
<span id="cb29-551"><a href="#cb29-551"></a><span class="in">```python</span></span>
<span id="cb29-552"><a href="#cb29-552"></a><span class="co"># S-Learner: single model with treatment as feature</span></span>
<span id="cb29-553"><a href="#cb29-553"></a>X_aug <span class="op">=</span> np.column_stack([X_sim, W_sim])</span>
<span id="cb29-554"><a href="#cb29-554"></a>model_s <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb29-555"><a href="#cb29-555"></a>model_s.fit(X_aug, Y_sim)</span>
<span id="cb29-556"><a href="#cb29-556"></a></span>
<span id="cb29-557"><a href="#cb29-557"></a><span class="co"># Predict under treatment and control</span></span>
<span id="cb29-558"><a href="#cb29-558"></a>tau_s <span class="op">=</span> (model_s.predict(np.column_stack([X_sim, np.ones(n)])) <span class="op">-</span></span>
<span id="cb29-559"><a href="#cb29-559"></a>         model_s.predict(np.column_stack([X_sim, np.zeros(n)])))</span>
<span id="cb29-560"><a href="#cb29-560"></a></span>
<span id="cb29-561"><a href="#cb29-561"></a><span class="bu">print</span>(<span class="ss">f"S-Learner correlation with true τ: </span><span class="sc">{</span>np<span class="sc">.</span>corrcoef(tau_sim, tau_s)[<span class="dv">0</span>,<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb29-562"><a href="#cb29-562"></a><span class="in">```</span></span>
<span id="cb29-563"><a href="#cb29-563"></a></span>
<span id="cb29-564"><a href="#cb29-564"></a>**Pros**: Simple, regularization shared</span>
<span id="cb29-565"><a href="#cb29-565"></a></span>
<span id="cb29-566"><a href="#cb29-566"></a>**Cons**: Treatment effect can be shrunk to zero</span>
<span id="cb29-567"><a href="#cb29-567"></a></span>
<span id="cb29-568"><a href="#cb29-568"></a><span class="fu">## X-Learner (Künzel et al. 2019)</span></span>
<span id="cb29-569"><a href="#cb29-569"></a></span>
<span id="cb29-570"><a href="#cb29-570"></a>Best for **imbalanced treatment** (few treated or few controls):</span>
<span id="cb29-571"><a href="#cb29-571"></a></span>
<span id="cb29-572"><a href="#cb29-572"></a><span class="ss">1. </span>Fit $\hat{\mu}_0, \hat{\mu}_1$ (T-learner)</span>
<span id="cb29-573"><a href="#cb29-573"></a><span class="ss">2. </span>Impute treatment effects:</span>
<span id="cb29-574"><a href="#cb29-574"></a><span class="ss">   - </span>Treated: $\tilde{D}_1 = Y_1 - \hat{\mu}_0(X_1)$</span>
<span id="cb29-575"><a href="#cb29-575"></a><span class="ss">   - </span>Control: $\tilde{D}_0 = \hat{\mu}_1(X_0) - Y_0$</span>
<span id="cb29-576"><a href="#cb29-576"></a><span class="ss">3. </span>Fit models: $\hat{\tau}_0(x), \hat{\tau}_1(x)$</span>
<span id="cb29-577"><a href="#cb29-577"></a><span class="ss">4. </span>Combine: $\hat{\tau}(x) = e(x) \hat{\tau}_0(x) + (1-e(x)) \hat{\tau}_1(x)$</span>
<span id="cb29-578"><a href="#cb29-578"></a></span>
<span id="cb29-579"><a href="#cb29-579"></a><span class="fu">## Comparison</span></span>
<span id="cb29-580"><a href="#cb29-580"></a></span>
<span id="cb29-581"><a href="#cb29-581"></a><span class="pp">|</span> Learner <span class="pp">|</span> Best When <span class="pp">|</span> Weakness <span class="pp">|</span></span>
<span id="cb29-582"><a href="#cb29-582"></a><span class="pp">|---------|-----------|----------|</span></span>
<span id="cb29-583"><a href="#cb29-583"></a><span class="pp">|</span> **T-Learner** <span class="pp">|</span> Balanced, large samples <span class="pp">|</span> High variance <span class="pp">|</span></span>
<span id="cb29-584"><a href="#cb29-584"></a><span class="pp">|</span> **S-Learner** <span class="pp">|</span> Small effects, regularization needed <span class="pp">|</span> Shrinks effects <span class="pp">|</span></span>
<span id="cb29-585"><a href="#cb29-585"></a><span class="pp">|</span> **X-Learner** <span class="pp">|</span> Imbalanced treatment <span class="pp">|</span> Complex, needs propensity <span class="pp">|</span></span>
<span id="cb29-586"><a href="#cb29-586"></a></span>
<span id="cb29-587"><a href="#cb29-587"></a><span class="fu"># Group Average Treatment Effects (GATES) {.unnumbered}</span></span>
<span id="cb29-588"><a href="#cb29-588"></a></span>
<span id="cb29-589"><a href="#cb29-589"></a><span class="fu">## Evaluating Heterogeneity</span></span>
<span id="cb29-590"><a href="#cb29-590"></a></span>
<span id="cb29-591"><a href="#cb29-591"></a>GATES groups units by predicted CATE and estimates average effects within each group:</span>
<span id="cb29-592"><a href="#cb29-592"></a></span>
<span id="cb29-595"><a href="#cb29-595"></a><span class="in">```{r}</span></span>
<span id="cb29-596"><a href="#cb29-596"></a><span class="co">#| label: gates</span></span>
<span id="cb29-597"><a href="#cb29-597"></a><span class="co">#| fig-cap: "GATES: Average effects by predicted CATE quartile"</span></span>
<span id="cb29-598"><a href="#cb29-598"></a><span class="co">#| eval: true</span></span>
<span id="cb29-599"><a href="#cb29-599"></a></span>
<span id="cb29-600"><a href="#cb29-600"></a><span class="co"># GATES analysis</span></span>
<span id="cb29-601"><a href="#cb29-601"></a>tau_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(cf)<span class="sc">$</span>predictions</span>
<span id="cb29-602"><a href="#cb29-602"></a></span>
<span id="cb29-603"><a href="#cb29-603"></a><span class="co"># Create quartiles</span></span>
<span id="cb29-604"><a href="#cb29-604"></a>df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb29-605"><a href="#cb29-605"></a>  <span class="fu">mutate</span>(</span>
<span id="cb29-606"><a href="#cb29-606"></a>    <span class="at">tau_hat =</span> tau_hat,</span>
<span id="cb29-607"><a href="#cb29-607"></a>    <span class="at">quartile =</span> <span class="fu">cut</span>(tau_hat,</span>
<span id="cb29-608"><a href="#cb29-608"></a>                   <span class="at">breaks =</span> <span class="fu">quantile</span>(tau_hat, <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="dv">1</span>)),</span>
<span id="cb29-609"><a href="#cb29-609"></a>                   <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Q1 (lowest)"</span>, <span class="st">"Q2"</span>, <span class="st">"Q3"</span>, <span class="st">"Q4 (highest)"</span>),</span>
<span id="cb29-610"><a href="#cb29-610"></a>                   <span class="at">include.lowest =</span> <span class="cn">TRUE</span>)</span>
<span id="cb29-611"><a href="#cb29-611"></a>  )</span>
<span id="cb29-612"><a href="#cb29-612"></a></span>
<span id="cb29-613"><a href="#cb29-613"></a><span class="co"># Compute GATES</span></span>
<span id="cb29-614"><a href="#cb29-614"></a>gates <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span></span>
<span id="cb29-615"><a href="#cb29-615"></a>  <span class="fu">group_by</span>(quartile) <span class="sc">%&gt;%</span></span>
<span id="cb29-616"><a href="#cb29-616"></a>  <span class="fu">summarise</span>(</span>
<span id="cb29-617"><a href="#cb29-617"></a>    <span class="at">mean_tau_true =</span> <span class="fu">mean</span>(tau_true),</span>
<span id="cb29-618"><a href="#cb29-618"></a>    <span class="at">mean_tau_hat =</span> <span class="fu">mean</span>(tau_hat),</span>
<span id="cb29-619"><a href="#cb29-619"></a>    <span class="at">n =</span> <span class="fu">n</span>(),</span>
<span id="cb29-620"><a href="#cb29-620"></a>    <span class="at">.groups =</span> <span class="st">"drop"</span></span>
<span id="cb29-621"><a href="#cb29-621"></a>  )</span>
<span id="cb29-622"><a href="#cb29-622"></a></span>
<span id="cb29-623"><a href="#cb29-623"></a><span class="co"># Plot</span></span>
<span id="cb29-624"><a href="#cb29-624"></a><span class="fu">ggplot</span>(gates, <span class="fu">aes</span>(<span class="at">x =</span> quartile)) <span class="sc">+</span></span>
<span id="cb29-625"><a href="#cb29-625"></a>  <span class="fu">geom_bar</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean_tau_true, <span class="at">fill =</span> <span class="st">"True"</span>), <span class="at">stat =</span> <span class="st">"identity"</span>,</span>
<span id="cb29-626"><a href="#cb29-626"></a>           <span class="at">position =</span> <span class="fu">position_dodge</span>(<span class="at">width =</span> <span class="fl">0.8</span>), <span class="at">width =</span> <span class="fl">0.35</span>) <span class="sc">+</span></span>
<span id="cb29-627"><a href="#cb29-627"></a>  <span class="fu">geom_bar</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean_tau_hat, <span class="at">fill =</span> <span class="st">"Estimated"</span>), <span class="at">stat =</span> <span class="st">"identity"</span>,</span>
<span id="cb29-628"><a href="#cb29-628"></a>           <span class="at">position =</span> <span class="fu">position_dodge</span>(<span class="at">width =</span> <span class="fl">0.8</span>), <span class="at">width =</span> <span class="fl">0.35</span>) <span class="sc">+</span></span>
<span id="cb29-629"><a href="#cb29-629"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"True"</span> <span class="ot">=</span> <span class="st">"#2ecc71"</span>, <span class="st">"Estimated"</span> <span class="ot">=</span> <span class="st">"#3498db"</span>)) <span class="sc">+</span></span>
<span id="cb29-630"><a href="#cb29-630"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Group Average Treatment Effects (GATES)"</span>,</span>
<span id="cb29-631"><a href="#cb29-631"></a>       <span class="at">subtitle =</span> <span class="st">"Causal forest correctly ranks effect heterogeneity"</span>,</span>
<span id="cb29-632"><a href="#cb29-632"></a>       <span class="at">x =</span> <span class="st">"Quartile of Predicted CATE"</span>, <span class="at">y =</span> <span class="st">"Average Treatment Effect"</span>) <span class="sc">+</span></span>
<span id="cb29-633"><a href="#cb29-633"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb29-634"><a href="#cb29-634"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>, <span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span>
<span id="cb29-635"><a href="#cb29-635"></a><span class="in">```</span></span>
<span id="cb29-636"><a href="#cb29-636"></a></span>
<span id="cb29-637"><a href="#cb29-637"></a><span class="fu">## Best Linear Predictor (BLP)</span></span>
<span id="cb29-638"><a href="#cb29-638"></a></span>
<span id="cb29-639"><a href="#cb29-639"></a>Which covariates **explain** heterogeneity?</span>
<span id="cb29-640"><a href="#cb29-640"></a></span>
<span id="cb29-643"><a href="#cb29-643"></a><span class="in">```{r}</span></span>
<span id="cb29-644"><a href="#cb29-644"></a><span class="co">#| label: blp</span></span>
<span id="cb29-645"><a href="#cb29-645"></a><span class="co">#| fig-cap: "Best linear predictor identifies X₁ as heterogeneity driver"</span></span>
<span id="cb29-646"><a href="#cb29-646"></a><span class="co">#| eval: true</span></span>
<span id="cb29-647"><a href="#cb29-647"></a></span>
<span id="cb29-648"><a href="#cb29-648"></a><span class="co"># Best linear projection</span></span>
<span id="cb29-649"><a href="#cb29-649"></a>blp <span class="ot">&lt;-</span> <span class="fu">best_linear_projection</span>(cf, X)</span>
<span id="cb29-650"><a href="#cb29-650"></a><span class="fu">print</span>(blp)</span>
<span id="cb29-651"><a href="#cb29-651"></a></span>
<span id="cb29-652"><a href="#cb29-652"></a><span class="co"># Visualize</span></span>
<span id="cb29-653"><a href="#cb29-653"></a>blp_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb29-654"><a href="#cb29-654"></a>  <span class="at">variable =</span> <span class="fu">c</span>(<span class="st">"Intercept"</span>, <span class="st">"X1"</span>, <span class="st">"X2"</span>),</span>
<span id="cb29-655"><a href="#cb29-655"></a>  <span class="at">estimate =</span> blp[, <span class="dv">1</span>],</span>
<span id="cb29-656"><a href="#cb29-656"></a>  <span class="at">se =</span> blp[, <span class="dv">2</span>]</span>
<span id="cb29-657"><a href="#cb29-657"></a>)</span>
<span id="cb29-658"><a href="#cb29-658"></a></span>
<span id="cb29-659"><a href="#cb29-659"></a><span class="fu">ggplot</span>(blp_df, <span class="fu">aes</span>(<span class="at">x =</span> variable, <span class="at">y =</span> estimate)) <span class="sc">+</span></span>
<span id="cb29-660"><a href="#cb29-660"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>, <span class="at">color =</span> <span class="st">"#3498db"</span>) <span class="sc">+</span></span>
<span id="cb29-661"><a href="#cb29-661"></a>  <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> estimate <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> se, <span class="at">ymax =</span> estimate <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> se),</span>
<span id="cb29-662"><a href="#cb29-662"></a>                <span class="at">width =</span> <span class="fl">0.2</span>, <span class="at">color =</span> <span class="st">"#3498db"</span>) <span class="sc">+</span></span>
<span id="cb29-663"><a href="#cb29-663"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb29-664"><a href="#cb29-664"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Best Linear Predictor of CATE"</span>,</span>
<span id="cb29-665"><a href="#cb29-665"></a>       <span class="at">subtitle =</span> <span class="st">"X₁ significantly predicts heterogeneity (coefficient ≈ 1.5)"</span>,</span>
<span id="cb29-666"><a href="#cb29-666"></a>       <span class="at">x =</span> <span class="cn">NULL</span>, <span class="at">y =</span> <span class="st">"Coefficient"</span>) <span class="sc">+</span></span>
<span id="cb29-667"><a href="#cb29-667"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb29-668"><a href="#cb29-668"></a><span class="in">```</span></span>
<span id="cb29-669"><a href="#cb29-669"></a></span>
<span id="cb29-670"><a href="#cb29-670"></a><span class="fu"># EconML: Microsoft's Causal ML Toolkit {.unnumbered}</span></span>
<span id="cb29-671"><a href="#cb29-671"></a></span>
<span id="cb29-672"><a href="#cb29-672"></a><span class="fu">## Overview</span></span>
<span id="cb29-673"><a href="#cb29-673"></a></span>
<span id="cb29-674"><a href="#cb29-674"></a>EconML provides a **unified API** for heterogeneous treatment effect estimation in Python.</span>
<span id="cb29-675"><a href="#cb29-675"></a></span>
<span id="cb29-676"><a href="#cb29-676"></a><span class="fu">## Key Estimators</span></span>
<span id="cb29-677"><a href="#cb29-677"></a></span>
<span id="cb29-678"><a href="#cb29-678"></a><span class="pp">|</span> Estimator <span class="pp">|</span> Description <span class="pp">|</span></span>
<span id="cb29-679"><a href="#cb29-679"></a><span class="pp">|-----------|-------------|</span></span>
<span id="cb29-680"><a href="#cb29-680"></a><span class="pp">|</span> <span class="in">`LinearDML`</span> <span class="pp">|</span> DML with linear final stage <span class="pp">|</span></span>
<span id="cb29-681"><a href="#cb29-681"></a><span class="pp">|</span> <span class="in">`CausalForestDML`</span> <span class="pp">|</span> Causal forest with DML <span class="pp">|</span></span>
<span id="cb29-682"><a href="#cb29-682"></a><span class="pp">|</span> <span class="in">`ForestDRLearner`</span> <span class="pp">|</span> Doubly robust forest <span class="pp">|</span></span>
<span id="cb29-683"><a href="#cb29-683"></a><span class="pp">|</span> <span class="in">`OrthoIV`</span> <span class="pp">|</span> Orthogonal IV learner <span class="pp">|</span></span>
<span id="cb29-684"><a href="#cb29-684"></a><span class="pp">|</span> <span class="in">`DynamicDML`</span> <span class="pp">|</span> Panel data <span class="pp">|</span></span>
<span id="cb29-685"><a href="#cb29-685"></a></span>
<span id="cb29-686"><a href="#cb29-686"></a><span class="fu">## Python Implementation</span></span>
<span id="cb29-687"><a href="#cb29-687"></a></span>
<span id="cb29-688"><a href="#cb29-688"></a><span class="in">```python</span></span>
<span id="cb29-689"><a href="#cb29-689"></a><span class="co"># EconML example</span></span>
<span id="cb29-690"><a href="#cb29-690"></a><span class="im">from</span> econml.dml <span class="im">import</span> LinearDML, CausalForestDML</span>
<span id="cb29-691"><a href="#cb29-691"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor, RandomForestClassifier</span>
<span id="cb29-692"><a href="#cb29-692"></a></span>
<span id="cb29-693"><a href="#cb29-693"></a><span class="co"># Setup</span></span>
<span id="cb29-694"><a href="#cb29-694"></a>X_hetero <span class="op">=</span> X_sim[:, :<span class="dv">3</span>]  <span class="co"># features for heterogeneity</span></span>
<span id="cb29-695"><a href="#cb29-695"></a>W_confound <span class="op">=</span> X_sim[:, <span class="dv">3</span>:]  <span class="co"># confounders</span></span>
<span id="cb29-696"><a href="#cb29-696"></a></span>
<span id="cb29-697"><a href="#cb29-697"></a><span class="co"># LinearDML</span></span>
<span id="cb29-698"><a href="#cb29-698"></a>est_linear <span class="op">=</span> LinearDML(</span>
<span id="cb29-699"><a href="#cb29-699"></a>    model_y<span class="op">=</span>RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>),</span>
<span id="cb29-700"><a href="#cb29-700"></a>    model_t<span class="op">=</span>RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>),</span>
<span id="cb29-701"><a href="#cb29-701"></a>    cv<span class="op">=</span><span class="dv">5</span></span>
<span id="cb29-702"><a href="#cb29-702"></a>)</span>
<span id="cb29-703"><a href="#cb29-703"></a>est_linear.fit(Y_sim, W_sim, X<span class="op">=</span>X_hetero, W<span class="op">=</span>W_confound)</span>
<span id="cb29-704"><a href="#cb29-704"></a></span>
<span id="cb29-705"><a href="#cb29-705"></a><span class="co"># Effects</span></span>
<span id="cb29-706"><a href="#cb29-706"></a>tau_linear <span class="op">=</span> est_linear.effect(X_hetero)</span>
<span id="cb29-707"><a href="#cb29-707"></a></span>
<span id="cb29-708"><a href="#cb29-708"></a><span class="co"># Inference</span></span>
<span id="cb29-709"><a href="#cb29-709"></a>tau_lower, tau_upper <span class="op">=</span> est_linear.effect_interval(X_hetero, alpha<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb29-710"><a href="#cb29-710"></a></span>
<span id="cb29-711"><a href="#cb29-711"></a><span class="co"># Summary</span></span>
<span id="cb29-712"><a href="#cb29-712"></a><span class="bu">print</span>(est_linear.summary())</span>
<span id="cb29-713"><a href="#cb29-713"></a><span class="in">```</span></span>
<span id="cb29-714"><a href="#cb29-714"></a></span>
<span id="cb29-715"><a href="#cb29-715"></a><span class="fu">## Unified API Pattern</span></span>
<span id="cb29-716"><a href="#cb29-716"></a></span>
<span id="cb29-717"><a href="#cb29-717"></a>All EconML estimators follow:</span>
<span id="cb29-718"><a href="#cb29-718"></a></span>
<span id="cb29-719"><a href="#cb29-719"></a><span class="in">```python</span></span>
<span id="cb29-720"><a href="#cb29-720"></a>est.fit(Y, T, X<span class="op">=</span>X, W<span class="op">=</span>W)           <span class="co"># fit (Y=outcome, T=treatment, X=hetero, W=confound)</span></span>
<span id="cb29-721"><a href="#cb29-721"></a>est.effect(X_test)                 <span class="co"># point estimates</span></span>
<span id="cb29-722"><a href="#cb29-722"></a>est.effect_interval(X_test)        <span class="co"># confidence intervals</span></span>
<span id="cb29-723"><a href="#cb29-723"></a>est.summary()                      <span class="co"># inference summary</span></span>
<span id="cb29-724"><a href="#cb29-724"></a><span class="in">```</span></span>
<span id="cb29-725"><a href="#cb29-725"></a></span>
<span id="cb29-726"><a href="#cb29-726"></a><span class="fu"># Applications in Macroeconomics {.unnumbered}</span></span>
<span id="cb29-727"><a href="#cb29-727"></a></span>
<span id="cb29-728"><a href="#cb29-728"></a><span class="fu">## Heterogeneous Policy Effects</span></span>
<span id="cb29-729"><a href="#cb29-729"></a></span>
<span id="cb29-730"><a href="#cb29-730"></a>**Question**: How do monetary policy effects vary across firms/regions/time?</span>
<span id="cb29-731"><a href="#cb29-731"></a></span>
<span id="cb29-732"><a href="#cb29-732"></a>**Approach**:</span>
<span id="cb29-733"><a href="#cb29-733"></a></span>
<span id="cb29-734"><a href="#cb29-734"></a><span class="ss">1. </span>Identify policy shocks (high-frequency, narrative)</span>
<span id="cb29-735"><a href="#cb29-735"></a><span class="ss">2. </span>Estimate heterogeneous effects using causal forests</span>
<span id="cb29-736"><a href="#cb29-736"></a><span class="ss">3. </span>Characterize which observables predict sensitivity</span>
<span id="cb29-737"><a href="#cb29-737"></a></span>
<span id="cb29-738"><a href="#cb29-738"></a><span class="fu">## Example: Cross-Country Monetary Transmission</span></span>
<span id="cb29-739"><a href="#cb29-739"></a></span>
<span id="cb29-740"><a href="#cb29-740"></a><span class="in">```r</span></span>
<span id="cb29-741"><a href="#cb29-741"></a><span class="co"># Do bank holdings predict constrained monetary response?</span></span>
<span id="cb29-742"><a href="#cb29-742"></a>cf_policy <span class="ot">&lt;-</span> <span class="fu">causal_forest</span>(</span>
<span id="cb29-743"><a href="#cb29-743"></a>  <span class="at">X =</span> <span class="fu">cbind</span>(bank_holdings, cbi_index, debt_gdp, trade_openness),</span>
<span id="cb29-744"><a href="#cb29-744"></a>  <span class="at">Y =</span> delta_inflation,</span>
<span id="cb29-745"><a href="#cb29-745"></a>  <span class="at">W =</span> tightening_dummy</span>
<span id="cb29-746"><a href="#cb29-746"></a>)</span>
<span id="cb29-747"><a href="#cb29-747"></a></span>
<span id="cb29-748"><a href="#cb29-748"></a><span class="co"># Which characteristics drive heterogeneity?</span></span>
<span id="cb29-749"><a href="#cb29-749"></a><span class="fu">variable_importance</span>(cf_policy)</span>
<span id="cb29-750"><a href="#cb29-750"></a></span>
<span id="cb29-751"><a href="#cb29-751"></a><span class="co"># Linear approximation</span></span>
<span id="cb29-752"><a href="#cb29-752"></a><span class="fu">best_linear_projection</span>(cf_policy,</span>
<span id="cb29-753"><a href="#cb29-753"></a>                       <span class="fu">cbind</span>(bank_holdings, cbi_index, debt_gdp))</span>
<span id="cb29-754"><a href="#cb29-754"></a><span class="in">```</span></span>
<span id="cb29-755"><a href="#cb29-755"></a></span>
<span id="cb29-756"><a href="#cb29-756"></a><span class="fu">## Fiscal Multiplier Heterogeneity</span></span>
<span id="cb29-757"><a href="#cb29-757"></a></span>
<span id="cb29-758"><a href="#cb29-758"></a>Do fiscal multipliers vary by:</span>
<span id="cb29-759"><a href="#cb29-759"></a></span>
<span id="cb29-760"><a href="#cb29-760"></a><span class="ss">- </span>Slack (output gap)?</span>
<span id="cb29-761"><a href="#cb29-761"></a><span class="ss">- </span>Monetary policy stance (ZLB)?</span>
<span id="cb29-762"><a href="#cb29-762"></a><span class="ss">- </span>Debt levels?</span>
<span id="cb29-763"><a href="#cb29-763"></a></span>
<span id="cb29-764"><a href="#cb29-764"></a>Causal forests can flexibly estimate:</span>
<span id="cb29-765"><a href="#cb29-765"></a>$$</span>
<span id="cb29-766"><a href="#cb29-766"></a>\text{Multiplier}(x) = \mathbb{E}<span class="co">[</span><span class="ot">\Delta Y \mid \text{Fiscal shock}, X = x</span><span class="co">]</span></span>
<span id="cb29-767"><a href="#cb29-767"></a>$$</span>
<span id="cb29-768"><a href="#cb29-768"></a></span>
<span id="cb29-769"><a href="#cb29-769"></a><span class="fu"># Practical Considerations {.unnumbered}</span></span>
<span id="cb29-770"><a href="#cb29-770"></a></span>
<span id="cb29-771"><a href="#cb29-771"></a><span class="fu">## Sample Size Requirements</span></span>
<span id="cb29-772"><a href="#cb29-772"></a></span>
<span id="cb29-773"><a href="#cb29-773"></a><span class="pp">|</span> Method <span class="pp">|</span> Minimum N <span class="pp">|</span> Recommended N <span class="pp">|</span></span>
<span id="cb29-774"><a href="#cb29-774"></a><span class="pp">|--------|-----------|---------------|</span></span>
<span id="cb29-775"><a href="#cb29-775"></a><span class="pp">|</span> ATE (Double ML) <span class="pp">|</span> 200 <span class="pp">|</span> 500+ <span class="pp">|</span></span>
<span id="cb29-776"><a href="#cb29-776"></a><span class="pp">|</span> CATE (Causal Forest) <span class="pp">|</span> 500 <span class="pp">|</span> 2000+ <span class="pp">|</span></span>
<span id="cb29-777"><a href="#cb29-777"></a><span class="pp">|</span> GATES <span class="pp">|</span> 1000 <span class="pp">|</span> 3000+ <span class="pp">|</span></span>
<span id="cb29-778"><a href="#cb29-778"></a><span class="pp">|</span> Variable Importance <span class="pp">|</span> 2000 <span class="pp">|</span> 5000+ <span class="pp">|</span></span>
<span id="cb29-779"><a href="#cb29-779"></a></span>
<span id="cb29-780"><a href="#cb29-780"></a><span class="fu">## Diagnostics</span></span>
<span id="cb29-781"><a href="#cb29-781"></a></span>
<span id="cb29-782"><a href="#cb29-782"></a><span class="fu">### Overlap Check</span></span>
<span id="cb29-783"><a href="#cb29-783"></a></span>
<span id="cb29-784"><a href="#cb29-784"></a><span class="in">```r</span></span>
<span id="cb29-785"><a href="#cb29-785"></a><span class="co"># Propensity score distribution</span></span>
<span id="cb29-786"><a href="#cb29-786"></a>e_hat <span class="ot">&lt;-</span> cf<span class="sc">$</span>W.hat</span>
<span id="cb29-787"><a href="#cb29-787"></a><span class="fu">hist</span>(e_hat, <span class="at">breaks =</span> <span class="dv">50</span>, <span class="at">main =</span> <span class="st">"Propensity Scores"</span>)</span>
<span id="cb29-788"><a href="#cb29-788"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.9</span>), <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb29-789"><a href="#cb29-789"></a></span>
<span id="cb29-790"><a href="#cb29-790"></a><span class="co"># Extreme values</span></span>
<span id="cb29-791"><a href="#cb29-791"></a><span class="fu">cat</span>(<span class="st">"Extreme propensity:"</span>, <span class="fu">mean</span>(e_hat <span class="sc">&lt;</span> <span class="fl">0.1</span> <span class="sc">|</span> e_hat <span class="sc">&gt;</span> <span class="fl">0.9</span>) <span class="sc">*</span> <span class="dv">100</span>, <span class="st">"%</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb29-792"><a href="#cb29-792"></a><span class="in">```</span></span>
<span id="cb29-793"><a href="#cb29-793"></a></span>
<span id="cb29-794"><a href="#cb29-794"></a><span class="fu">### Calibration Test</span></span>
<span id="cb29-795"><a href="#cb29-795"></a></span>
<span id="cb29-796"><a href="#cb29-796"></a><span class="in">```r</span></span>
<span id="cb29-797"><a href="#cb29-797"></a><span class="co"># Is there actually heterogeneity?</span></span>
<span id="cb29-798"><a href="#cb29-798"></a><span class="fu">test_calibration</span>(cf)</span>
<span id="cb29-799"><a href="#cb29-799"></a><span class="co"># Look for significant "differential.forest.prediction"</span></span>
<span id="cb29-800"><a href="#cb29-800"></a><span class="in">```</span></span>
<span id="cb29-801"><a href="#cb29-801"></a></span>
<span id="cb29-802"><a href="#cb29-802"></a><span class="fu">### AUTOC (Targeting Quality)</span></span>
<span id="cb29-803"><a href="#cb29-803"></a></span>
<span id="cb29-804"><a href="#cb29-804"></a><span class="in">```r</span></span>
<span id="cb29-805"><a href="#cb29-805"></a><span class="co"># Area Under the TOC Curve</span></span>
<span id="cb29-806"><a href="#cb29-806"></a>rate <span class="ot">&lt;-</span> <span class="fu">rank_average_treatment_effect</span>(cf, X[, <span class="dv">1</span>])</span>
<span id="cb29-807"><a href="#cb29-807"></a><span class="fu">print</span>(rate)  <span class="co"># CI should exclude 0</span></span>
<span id="cb29-808"><a href="#cb29-808"></a><span class="in">```</span></span>
<span id="cb29-809"><a href="#cb29-809"></a></span>
<span id="cb29-810"><a href="#cb29-810"></a><span class="fu">## Common Pitfalls</span></span>
<span id="cb29-811"><a href="#cb29-811"></a></span>
<span id="cb29-812"><a href="#cb29-812"></a><span class="ss">1. </span>**Causal ML doesn't solve identification**: Still need unconfoundedness</span>
<span id="cb29-813"><a href="#cb29-813"></a><span class="ss">2. </span>**Overfitting CATE**: Use honest forests, cross-validation</span>
<span id="cb29-814"><a href="#cb29-814"></a><span class="ss">3. </span>**Noise as heterogeneity**: Run calibration tests</span>
<span id="cb29-815"><a href="#cb29-815"></a><span class="ss">4. </span>**Overlap violations**: Check propensity scores, trim extremes</span>
<span id="cb29-816"><a href="#cb29-816"></a><span class="ss">5. </span>**Small samples**: CATE unreliable with N &lt; 500</span>
<span id="cb29-817"><a href="#cb29-817"></a></span>
<span id="cb29-818"><a href="#cb29-818"></a><span class="fu"># Summary {.unnumbered}</span></span>
<span id="cb29-819"><a href="#cb29-819"></a></span>
<span id="cb29-820"><a href="#cb29-820"></a><span class="pp">|</span> Method <span class="pp">|</span> Purpose <span class="pp">|</span> Package <span class="pp">|</span></span>
<span id="cb29-821"><a href="#cb29-821"></a><span class="pp">|--------|---------|---------|</span></span>
<span id="cb29-822"><a href="#cb29-822"></a><span class="pp">|</span> **Causal Forest** <span class="pp">|</span> Heterogeneous treatment effects <span class="pp">|</span> <span class="in">`grf`</span> (R) <span class="pp">|</span></span>
<span id="cb29-823"><a href="#cb29-823"></a><span class="pp">|</span> **Double ML** <span class="pp">|</span> ATE with high-dimensional controls <span class="pp">|</span> <span class="in">`DoubleML`</span> (Python/R) <span class="pp">|</span></span>
<span id="cb29-824"><a href="#cb29-824"></a><span class="pp">|</span> **EconML** <span class="pp">|</span> Unified CATE estimation <span class="pp">|</span> <span class="in">`econml`</span> (Python) <span class="pp">|</span></span>
<span id="cb29-825"><a href="#cb29-825"></a><span class="pp">|</span> **Meta-Learners** <span class="pp">|</span> T/S/X strategies for CATE <span class="pp">|</span> Various <span class="pp">|</span></span>
<span id="cb29-826"><a href="#cb29-826"></a></span>
<span id="cb29-827"><a href="#cb29-827"></a>::: {.callout-tip}</span>
<span id="cb29-828"><a href="#cb29-828"></a><span class="fu">## For Macro Applications</span></span>
<span id="cb29-829"><a href="#cb29-829"></a></span>
<span id="cb29-830"><a href="#cb29-830"></a><span class="ss">1. </span>**Sample sizes matter**: Cross-country panels may be too small for CATE</span>
<span id="cb29-831"><a href="#cb29-831"></a><span class="ss">2. </span>**Identification first**: Causal ML requires the same assumptions as traditional methods</span>
<span id="cb29-832"><a href="#cb29-832"></a><span class="ss">3. </span>**Focus on BLP and GATES**: Which characteristics predict heterogeneity?</span>
<span id="cb29-833"><a href="#cb29-833"></a><span class="ss">4. </span>**Aggregation concerns**: Individual effects may aggregate differently at macro level</span>
<span id="cb29-834"><a href="#cb29-834"></a>:::</span>
<span id="cb29-835"><a href="#cb29-835"></a></span>
<span id="cb29-836"><a href="#cb29-836"></a><span class="fu"># Key References {.unnumbered}</span></span>
<span id="cb29-837"><a href="#cb29-837"></a></span>
<span id="cb29-838"><a href="#cb29-838"></a><span class="fu">## Foundational</span></span>
<span id="cb29-839"><a href="#cb29-839"></a></span>
<span id="cb29-840"><a href="#cb29-840"></a><span class="ss">- </span>**Athey &amp; Imbens (2016)** "Recursive Partitioning for Heterogeneous Causal Effects" PNAS</span>
<span id="cb29-841"><a href="#cb29-841"></a><span class="ss">- </span>**Wager &amp; Athey (2018)** "Estimation and Inference of Heterogeneous Treatment Effects using Random Forests" JASA</span>
<span id="cb29-842"><a href="#cb29-842"></a><span class="ss">- </span>**Chernozhukov et al. (2018)** "Double/Debiased Machine Learning" Econometrics Journal</span>
<span id="cb29-843"><a href="#cb29-843"></a></span>
<span id="cb29-844"><a href="#cb29-844"></a><span class="fu">## Extensions</span></span>
<span id="cb29-845"><a href="#cb29-845"></a></span>
<span id="cb29-846"><a href="#cb29-846"></a><span class="ss">- </span>**Künzel et al. (2019)** "Metalearners for Heterogeneous Treatment Effects" PNAS</span>
<span id="cb29-847"><a href="#cb29-847"></a><span class="ss">- </span>**Athey &amp; Wager (2021)** "Policy Learning with Observational Data" Econometrica</span>
<span id="cb29-848"><a href="#cb29-848"></a><span class="ss">- </span>**Kennedy (2022)** "Optimal Doubly Robust Estimation of Heterogeneous Causal Effects"</span>
<span id="cb29-849"><a href="#cb29-849"></a></span>
<span id="cb29-850"><a href="#cb29-850"></a><span class="fu">## Resources</span></span>
<span id="cb29-851"><a href="#cb29-851"></a></span>
<span id="cb29-852"><a href="#cb29-852"></a><span class="ss">- </span>**Causal ML Book**: https://causalml-book.org/</span>
<span id="cb29-853"><a href="#cb29-853"></a><span class="ss">- </span>**ML for Economists**: https://github.com/ml4econ/lecture-notes-2025</span>
<span id="cb29-854"><a href="#cb29-854"></a><span class="ss">- </span>**grf Documentation**: https://grf-labs.github.io/grf/</span>
<span id="cb29-855"><a href="#cb29-855"></a><span class="ss">- </span>**EconML**: https://github.com/py-why/EconML</span>
<span id="cb29-856"><a href="#cb29-856"></a><span class="ss">- </span>**DoubleML**: https://github.com/DoubleML/doubleml-for-py</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Mastering Empirical Macroeconometrics by Bijoy Ratan Ghosh</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/bijoyratanghosh/empirical-macro-curriculum/edit/main/chapters/13_causal_ml.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/bijoyratanghosh/empirical-macro-curriculum/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Built with <a href="https://quarto.org/">Quarto</a></p>
</div>
  </div>
</footer>




</body></html>